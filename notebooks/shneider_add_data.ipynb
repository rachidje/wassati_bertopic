{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cattiaux/anaconda3/envs/wassati/lib/python3.9/site-packages/umap/distances.py:1063: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/home/cattiaux/anaconda3/envs/wassati/lib/python3.9/site-packages/umap/distances.py:1071: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/home/cattiaux/anaconda3/envs/wassati/lib/python3.9/site-packages/umap/distances.py:1086: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/home/cattiaux/anaconda3/envs/wassati/lib/python3.9/site-packages/umap/umap_.py:660: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import copy\n",
    "import pickle\n",
    "from bertopic import BERTopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_41213/456796116.py:1: DtypeWarning: Columns (5,6,14,18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_old = pd.read_csv(\"../data/csv_files/schneider.csv\")\n"
     ]
    }
   ],
   "source": [
    "df_old = pd.read_csv(\"../data/csv_files/schneider.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from utils.schneider import countries_to_update, text_data_column, words_to_filter, replacements\n",
    "from preprocessing.dataLoaders.schneider_data_loader import SchneiderDataLoader\n",
    "from preprocessing.preprocessing import Preprocessor\n",
    "\n",
    "df = pd.read_csv(\"../data/csv_files/schneider_2023.csv\")\n",
    "schneiderDataLoader = SchneiderDataLoader(df, countries_to_update)\n",
    "preprocessing = Preprocessor(\n",
    "    schneiderDataLoader, \n",
    "    text_data_column,\n",
    "    words_to_filter,\n",
    "    replacements\n",
    ")\n",
    "\n",
    "df_2023_preprocessed_full = preprocessing.preprocess()\n",
    "# Filter rows based on 'non_empty_rows' column\n",
    "df_2023_preprocessed = df_2023_preprocessed_full[df_2023_preprocessed_full['non_empty_rows']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 17\u001b[0m\n\u001b[1;32m     13\u001b[0m         topics, probs, embeddings, docs \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m topic_model, topics, probs, embeddings, docs\n\u001b[0;32m---> 17\u001b[0m topic_model, topics, probs, embeddings, docs \u001b[38;5;241m=\u001b[39m \u001b[43mload_bertopic_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../models/raw_keybert_bertopic_model\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_merged_model\u001b[39m(docs, bertopic_model, topics_to_merge_dict, label_names_dict):\n\u001b[1;32m     20\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;124;03m    Create a new BERTopic model by merging topics from an existing model.\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;124;03m        BERTopic: The resulting merged BERTopic model.\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[4], line 9\u001b[0m, in \u001b[0;36mload_bertopic_model\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mLoad a BERTopic model and associated data from a file.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03m:param filename: The name of the file to load the data from.\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124;03m:return: A tuple containing the loaded BERTopic model, topics, probs, and docs variables.\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Load the BERTopic model\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m topic_model \u001b[38;5;241m=\u001b[39m \u001b[43mBERTopic\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Load the topics, probs, and docs variables\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filename \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_data.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "File \u001b[0;32m~/anaconda3/envs/wassati/lib/python3.9/site-packages/bertopic/_bertopic.py:2998\u001b[0m, in \u001b[0;36mBERTopic.load\u001b[0;34m(cls, path, embedding_model)\u001b[0m\n\u001b[1;32m   2996\u001b[0m             topic_model\u001b[38;5;241m.\u001b[39membedding_model \u001b[38;5;241m=\u001b[39m select_backend(embedding_model)\n\u001b[1;32m   2997\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2998\u001b[0m             topic_model \u001b[38;5;241m=\u001b[39m \u001b[43mjoblib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2999\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m topic_model\n\u001b[1;32m   3001\u001b[0m \u001b[38;5;66;03m# Load from directory or HF\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/wassati/lib/python3.9/site-packages/joblib/numpy_pickle.py:648\u001b[0m, in \u001b[0;36mload\u001b[0;34m(filename, mmap_mode)\u001b[0m\n\u001b[1;32m    646\u001b[0m     filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(fobj, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    647\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _read_fileobject(fobj, filename, mmap_mode) \u001b[38;5;28;01mas\u001b[39;00m fobj:\n\u001b[0;32m--> 648\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43m_unpickle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    649\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    650\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "File \u001b[0;32m~/anaconda3/envs/wassati/lib/python3.9/site-packages/joblib/numpy_pickle.py:577\u001b[0m, in \u001b[0;36m_unpickle\u001b[0;34m(fobj, filename, mmap_mode)\u001b[0m\n\u001b[1;32m    575\u001b[0m obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    576\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 577\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m unpickler\u001b[38;5;241m.\u001b[39mcompat_mode:\n\u001b[1;32m    579\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe file \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m has been generated with a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    580\u001b[0m                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjoblib version less than 0.10. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    581\u001b[0m                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease regenerate this pickle file.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    582\u001b[0m                       \u001b[38;5;241m%\u001b[39m filename,\n\u001b[1;32m    583\u001b[0m                       \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/wassati/lib/python3.9/pickle.py:1212\u001b[0m, in \u001b[0;36m_Unpickler.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1210\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEOFError\u001b[39;00m\n\u001b[1;32m   1211\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, bytes_types)\n\u001b[0;32m-> 1212\u001b[0m         \u001b[43mdispatch\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1213\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _Stop \u001b[38;5;28;01mas\u001b[39;00m stopinst:\n\u001b[1;32m   1214\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m stopinst\u001b[38;5;241m.\u001b[39mvalue\n",
      "File \u001b[0;32m~/anaconda3/envs/wassati/lib/python3.9/pickle.py:1589\u001b[0m, in \u001b[0;36m_Unpickler.load_reduce\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1587\u001b[0m args \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39mpop()\n\u001b[1;32m   1588\u001b[0m func \u001b[38;5;241m=\u001b[39m stack[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m-> 1589\u001b[0m stack[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/wassati/lib/python3.9/site-packages/torch/storage.py:241\u001b[0m, in \u001b[0;36m_load_from_bytes\u001b[0;34m(b)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_load_from_bytes\u001b[39m(b):\n\u001b[0;32m--> 241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBytesIO\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/wassati/lib/python3.9/site-packages/torch/serialization.py:815\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    814\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 815\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_legacy_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopened_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/wassati/lib/python3.9/site-packages/torch/serialization.py:1043\u001b[0m, in \u001b[0;36m_legacy_load\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1041\u001b[0m unpickler \u001b[38;5;241m=\u001b[39m UnpicklerWrapper(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[1;32m   1042\u001b[0m unpickler\u001b[38;5;241m.\u001b[39mpersistent_load \u001b[38;5;241m=\u001b[39m persistent_load\n\u001b[0;32m-> 1043\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1045\u001b[0m deserialized_storage_keys \u001b[38;5;241m=\u001b[39m pickle_module\u001b[38;5;241m.\u001b[39mload(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[1;32m   1047\u001b[0m offset \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mtell() \u001b[38;5;28;01mif\u001b[39;00m f_should_read_directly \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/wassati/lib/python3.9/site-packages/torch/serialization.py:980\u001b[0m, in \u001b[0;36m_legacy_load.<locals>.persistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m    976\u001b[0m     obj\u001b[38;5;241m.\u001b[39m_torch_load_uninitialized \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    977\u001b[0m     \u001b[38;5;66;03m# TODO: Once we decide to break serialization FC, we can\u001b[39;00m\n\u001b[1;32m    978\u001b[0m     \u001b[38;5;66;03m# stop wrapping with TypedStorage\u001b[39;00m\n\u001b[1;32m    979\u001b[0m     typed_storage \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstorage\u001b[38;5;241m.\u001b[39mTypedStorage(\n\u001b[0;32m--> 980\u001b[0m         wrap_storage\u001b[38;5;241m=\u001b[39m\u001b[43mrestore_location\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    981\u001b[0m         dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m    982\u001b[0m         _internal\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    983\u001b[0m     deserialized_objects[root_key] \u001b[38;5;241m=\u001b[39m typed_storage\n\u001b[1;32m    984\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/wassati/lib/python3.9/site-packages/torch/serialization.py:217\u001b[0m, in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_restore_location\u001b[39m(storage, location):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _, _, fn \u001b[38;5;129;01min\u001b[39;00m _package_registry:\n\u001b[0;32m--> 217\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    219\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/envs/wassati/lib/python3.9/site-packages/torch/serialization.py:182\u001b[0m, in \u001b[0;36m_cuda_deserialize\u001b[0;34m(obj, location)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_cuda_deserialize\u001b[39m(obj, location):\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m location\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 182\u001b[0m         device \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_cuda_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    183\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_torch_load_uninitialized\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    184\u001b[0m             \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice(device):\n",
      "File \u001b[0;32m~/anaconda3/envs/wassati/lib/python3.9/site-packages/torch/serialization.py:166\u001b[0m, in \u001b[0;36mvalidate_cuda_device\u001b[0;34m(location)\u001b[0m\n\u001b[1;32m    163\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_get_device_index(location, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[0;32m--> 166\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAttempting to deserialize object on a CUDA \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    167\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice but torch.cuda.is_available() is False. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    168\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIf you are running on a CPU-only machine, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    169\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplease use torch.load with map_location=torch.device(\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    170\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mto map your storages to the CPU.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    171\u001b[0m device_count \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice_count()\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m device_count:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU."
     ]
    }
   ],
   "source": [
    "def load_bertopic_model(filename):\n",
    "    \"\"\"\n",
    "    Load a BERTopic model and associated data from a file.\n",
    "    \n",
    "    :param filename: The name of the file to load the data from.\n",
    "    :return: A tuple containing the loaded BERTopic model, topics, probs, and docs variables.\n",
    "    \"\"\"\n",
    "    # Load the BERTopic model\n",
    "    topic_model = BERTopic.load(filename)\n",
    "    \n",
    "    # Load the topics, probs, and docs variables\n",
    "    with open(filename + '_data.pkl', 'rb') as f:\n",
    "        topics, probs, embeddings, docs = pickle.load(f)\n",
    "    \n",
    "    return topic_model, topics, probs, embeddings, docs\n",
    "\n",
    "topic_model, topics, probs, embeddings, docs = load_bertopic_model('../models/raw_keybert_bertopic_model')\n",
    "\n",
    "def create_merged_model(docs, bertopic_model, topics_to_merge_dict, label_names_dict):\n",
    "    \"\"\"\n",
    "    Create a new BERTopic model by merging topics from an existing model.\n",
    "\n",
    "    This function takes as input a list of documents `docs`, an existing BERTopic model `bertopic_model`, a dictionary `topics_to_merge_dict` specifying which topics to merge, and a dictionary `label_names_dict` specifying the labels for the merged topics.\n",
    "\n",
    "    The function creates a deep copy of the input BERTopic model and merges the specified topics using the `merge_topics` method. Then, it sets the topic labels for the merged model using the `set_topic_labels` method and the provided `label_names_dict`.\n",
    "\n",
    "    The resulting merged BERTopic model is then returned.\n",
    "\n",
    "    Parameters:\n",
    "        docs (list): A list of documents used to fit the BERTopic model.\n",
    "        bertopic_model (BERTopic): The input BERTopic model to be merged.\n",
    "        topics_to_merge_dict (dict): A dictionary specifying which topics to merge. The keys are the topic numbers to be merged, and the values are the topic numbers into which they should be merged.\n",
    "        label_names_dict (dict): A dictionary specifying the labels for the merged topics. The keys are the topic numbers, and the values are the corresponding labels.\n",
    "\n",
    "    Returns:\n",
    "        BERTopic: The resulting merged BERTopic model.\n",
    "    \"\"\"\n",
    "    topic_model_merged = copy.deepcopy(bertopic_model)\n",
    "    topic_model_merged.merge_topics(docs, topics_to_merge_dict)\n",
    "\n",
    "    # Create a dictionary to match the aggregated name to their corresponding topic number\n",
    "    mergedtopic_labels_dict = {i-1: item for i, item in enumerate(label_names_dict)}\n",
    "    # Set topic labels for the aggregated model\n",
    "    topic_model_merged.set_topic_labels(mergedtopic_labels_dict)\n",
    "\n",
    "    return topic_model_merged### Création du modèle bertopic aggrégé pour topics finaux\n",
    "\n",
    "# List of topics numbers. Each value of this list is a list that contains the topic number of the topics to join together\n",
    "topics_to_merge = [ [42,3,0,13], #Delivery Deadlines : challenges and strategies involved in managing delivery deadlines in logistics operations. (vert)\n",
    "                    [20,50,27], #Quotation and Pricing Strategies (vert bas)\n",
    "                    [35,32], #Touch Panels and Screens (rouge, haut)\n",
    "                    [40,36], #Frequency Converters : frequency converters used in industrial applications and the technical support provided by manufacturers and suppliers (rouge, suite)\n",
    "                    [37,21,6,12,9,4,1,14,16,31,19], #“Automation Components” : hardware and software components used in industrial automation systems. (rouge centre)\n",
    "                    [33,46,8], #Product Evaluation : evaluate the quality, affordability and reliability of products and services (rouge, fin)\n",
    "                    [44,51,23,41,49,57,22], #Customer Support : Reliability and Quality in Customer Service and Support (bleu ciel)\n",
    "                    [58,59], #Quick Customer Service (marron)\n",
    "                    [38,10,26,52,39,43], #Problem Solving and Communication (focus on the importance of being efficient and precise when solving problems) (jaune)\n",
    "                    [45,47,55,53,54], #Assistance and Guidance (noir)\n",
    "                    [29,30,11,24], #Power Supply Issues (2e vert, haut)\n",
    "                    [7,5,2,25,15,34,18,28,17], #Technical Support (2e vert, bas)\n",
    "                    [48,56] #None : positive feedback (2e rouge)\n",
    "]\n",
    "\n",
    "label_names_postmerge = [\n",
    "    \"Outliers\",\n",
    "    \"Automation Components\",\n",
    "    \"Technical Support\",\n",
    "    \"Delivery Deadlines\",\n",
    "    \"Problem Solving & Comm\",\n",
    "    \"Power Supply Issues\",\n",
    "    \"Customer Support\", #Reliability and Quality in Customer Service and Support\n",
    "    \"Product Evaluation\",\n",
    "    \"Pricing\", #Quotation and Pricing Strategies\n",
    "    \"Assistance\", #Assistance and Guidance\n",
    "    \"Touch Screens\", #Touch Panels and Screens\n",
    "    \"Frequency Converters\",\n",
    "    \"Positive feedback\",\n",
    "    \"Quick Customer Service\"\n",
    "    ]\n",
    "\n",
    "# Set the topic names for the new aggregated topic\n",
    "# It must match the order from the topics_to_merge list\n",
    "label_names = [\"Delivery Deadlines\",\n",
    "    \"Pricing\", #Quotation and Pricing Strategies\n",
    "    \"Touch Screens\", #Touch Panels and Screens\n",
    "    \"Frequency Converters\",\n",
    "    \"Automation Components\",\n",
    "    \"Product Evaluation\",\n",
    "    \"Customer Support\", #Reliability and Quality in Customer Service and Support\n",
    "    \"Quick Customer Service\",\n",
    "    \"Problem Solving & Comm\",\n",
    "    \"Assistance\", #Assistance and Guidance\n",
    "    \"Power Supply Issues\",\n",
    "    \"Technical Support\",\n",
    "    \"positive feedback\"]\n",
    "\n",
    "topic_labels_dict = {}\n",
    "topic_labels_dict[-1]=\"Outliers\"\n",
    "for i in range(len(topics_to_merge)):\n",
    "    for topic in topics_to_merge[i]:\n",
    "        topic_labels_dict[topic] = label_names[i]\n",
    "\n",
    "# Create a new merged bertopic model \n",
    "topic_model_merged = create_merged_model(docs, topic_model, topics_to_merge, label_names_postmerge)\n",
    "\n",
    "# topic_model_merged = copy.deepcopy(topic_model)\n",
    "# topic_model_merged.set_topic_labels(topic_labels_dict)\n",
    "# topic_model_merged.merge_topics(docs, topics_to_merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2023_preprocessed.reset_index(drop=True, inplace=True)\n",
    "new_topics, new_probs = topic_model_merged.transform(df_2023_preprocessed['processed_data'])\n",
    "\n",
    "# Now, you can merge the new dataframe with the old one\n",
    "# df_labelled = pd.concat([df_labelled, df_2023_preprocessed])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the topic and keywords for the new data\n",
    "new_topic_keywords = {}\n",
    "n = 10  # Number of keywords to include\n",
    "for topic in topic_model_merged.get_topics().keys():\n",
    "    topic_words = [word for word, _ in topic_model_merged.get_topic(topic)[:n]]\n",
    "    new_topic_keywords[topic] = \", \".join(topic_words)\n",
    "\n",
    "# Add the topics and keywords to the new dataframe\n",
    "df_2023_preprocessed['topic'] = new_topics\n",
    "df_2023_preprocessed['keywords'] = df_2023_preprocessed['topic'].map(new_topic_keywords)\n",
    "\n",
    "# Add the label column to the new dataframe\n",
    "mergedtopic_labels_dict = {i-1: item for i, item in enumerate(label_names_postmerge)}\n",
    "df_2023_preprocessed['label'] = df_2023_preprocessed['topic'].map(mergedtopic_labels_dict)\n",
    "\n",
    "# Get a list of the topics in the correct order, excluding topic -1\n",
    "topic_order = [topic for topic in topic_model_merged.get_topics().keys() if topic != -1]\n",
    "\n",
    "# Create a dictionary where the keys are the topic labels and the values are the probabilities\n",
    "new_proba_dict = []\n",
    "for proba in new_probs:\n",
    "    new_proba_dict.append(dict(sorted(zip(topic_order, proba), key=lambda item: item[1], reverse=True)))\n",
    "    \n",
    "# Add the proba_dict column to the new dataframe\n",
    "df_2023_preprocessed['proba_dict'] = new_proba_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>processed_data</th>\n",
       "      <th>topic</th>\n",
       "      <th>keywords</th>\n",
       "      <th>label</th>\n",
       "      <th>proba_dict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>The case cannot be closed yet. The variator is...</td>\n",
       "      <td>-1</td>\n",
       "      <td>customer service, delivery time, sales, techni...</td>\n",
       "      <td>Outliers</td>\n",
       "      <td>{5: 0.4971376656629934, 1: 0.18351327926820915...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>You kindly provided additional information in ...</td>\n",
       "      <td>-1</td>\n",
       "      <td>customer service, delivery time, sales, techni...</td>\n",
       "      <td>Outliers</td>\n",
       "      <td>{3: 0.5921793282262936, 8: 0.02130923580118823...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>Delivery date adjustment not carried out!</td>\n",
       "      <td>2</td>\n",
       "      <td>delivery time, delays, delivery date, deliveri...</td>\n",
       "      <td>Delivery Deadlines</td>\n",
       "      <td>{2: 0.37335230490884497, 0: 0.1247352399500280...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29</td>\n",
       "      <td>Very good service, very interactive and the at...</td>\n",
       "      <td>1</td>\n",
       "      <td>technical support, response time, customer ser...</td>\n",
       "      <td>Technical Support</td>\n",
       "      <td>{1: 0.9511487162523243, 5: 3.0232526310585277e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36</td>\n",
       "      <td>Reliable and quick offer</td>\n",
       "      <td>7</td>\n",
       "      <td>pricing, prices, discount, quotation, orders, ...</td>\n",
       "      <td>Pricing</td>\n",
       "      <td>{7: 0.054763016492342505, 0: 0.039560743994227...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>40</td>\n",
       "      <td>Nothing. for now we are satisfied with both th...</td>\n",
       "      <td>7</td>\n",
       "      <td>pricing, prices, discount, quotation, orders, ...</td>\n",
       "      <td>Pricing</td>\n",
       "      <td>{7: 0.6985103184838195, 0: 0.00366780982522584...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>42</td>\n",
       "      <td>Even though 2 months have passed since the ord...</td>\n",
       "      <td>-1</td>\n",
       "      <td>customer service, delivery time, sales, techni...</td>\n",
       "      <td>Outliers</td>\n",
       "      <td>{5: 0.15332537003148491, 1: 0.0869908212703196...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>43</td>\n",
       "      <td>Nice nd excellent work by Schneider worker spa...</td>\n",
       "      <td>0</td>\n",
       "      <td>technical support, programmable logic controll...</td>\n",
       "      <td>Automation Components</td>\n",
       "      <td>{0: 0.2672348851927576, 5: 0.04677892258495698...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>45</td>\n",
       "      <td>Mr. Melih Solmaz followed the issue closely, a...</td>\n",
       "      <td>-1</td>\n",
       "      <td>customer service, delivery time, sales, techni...</td>\n",
       "      <td>Outliers</td>\n",
       "      <td>{5: 0.15871219627779123, 1: 0.0970748022941245...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>46</td>\n",
       "      <td>I received help with concise and quick answers...</td>\n",
       "      <td>-1</td>\n",
       "      <td>customer service, delivery time, sales, techni...</td>\n",
       "      <td>Outliers</td>\n",
       "      <td>{1: 0.21914335128108423, 5: 0.1672696371400092...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                     processed_data  topic  \\\n",
       "0   7  The case cannot be closed yet. The variator is...     -1   \n",
       "1  12  You kindly provided additional information in ...     -1   \n",
       "2  28          Delivery date adjustment not carried out!      2   \n",
       "3  29  Very good service, very interactive and the at...      1   \n",
       "4  36                           Reliable and quick offer      7   \n",
       "5  40  Nothing. for now we are satisfied with both th...      7   \n",
       "6  42  Even though 2 months have passed since the ord...     -1   \n",
       "7  43  Nice nd excellent work by Schneider worker spa...      0   \n",
       "8  45  Mr. Melih Solmaz followed the issue closely, a...     -1   \n",
       "9  46  I received help with concise and quick answers...     -1   \n",
       "\n",
       "                                            keywords                  label  \\\n",
       "0  customer service, delivery time, sales, techni...               Outliers   \n",
       "1  customer service, delivery time, sales, techni...               Outliers   \n",
       "2  delivery time, delays, delivery date, deliveri...     Delivery Deadlines   \n",
       "3  technical support, response time, customer ser...      Technical Support   \n",
       "4  pricing, prices, discount, quotation, orders, ...                Pricing   \n",
       "5  pricing, prices, discount, quotation, orders, ...                Pricing   \n",
       "6  customer service, delivery time, sales, techni...               Outliers   \n",
       "7  technical support, programmable logic controll...  Automation Components   \n",
       "8  customer service, delivery time, sales, techni...               Outliers   \n",
       "9  customer service, delivery time, sales, techni...               Outliers   \n",
       "\n",
       "                                          proba_dict  \n",
       "0  {5: 0.4971376656629934, 1: 0.18351327926820915...  \n",
       "1  {3: 0.5921793282262936, 8: 0.02130923580118823...  \n",
       "2  {2: 0.37335230490884497, 0: 0.1247352399500280...  \n",
       "3  {1: 0.9511487162523243, 5: 3.0232526310585277e...  \n",
       "4  {7: 0.054763016492342505, 0: 0.039560743994227...  \n",
       "5  {7: 0.6985103184838195, 0: 0.00366780982522584...  \n",
       "6  {5: 0.15332537003148491, 1: 0.0869908212703196...  \n",
       "7  {0: 0.2672348851927576, 5: 0.04677892258495698...  \n",
       "8  {5: 0.15871219627779123, 1: 0.0970748022941245...  \n",
       "9  {1: 0.21914335128108423, 5: 0.1672696371400092...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2023_preprocessed.columns\n",
    "# len(df_2023_preprocessed_full)\n",
    "df_2023_preprocessed[[\"id\",\"processed_data\",\"topic\",\"keywords\",\"label\",\"proba_dict\"]].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wassati",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
