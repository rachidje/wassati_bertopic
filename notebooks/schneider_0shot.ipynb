{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cattiaux/anaconda3/envs/wassati/lib/python3.9/site-packages/umap/distances.py:1063: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/home/cattiaux/anaconda3/envs/wassati/lib/python3.9/site-packages/umap/distances.py:1071: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/home/cattiaux/anaconda3/envs/wassati/lib/python3.9/site-packages/umap/distances.py:1086: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/home/cattiaux/anaconda3/envs/wassati/lib/python3.9/site-packages/umap/umap_.py:660: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import ast\n",
    "import os\n",
    "import copy\n",
    "import nltk\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.io as pio\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import random\n",
    "import ipywidgets as widgets\n",
    "\n",
    "from IPython.display import display, clear_output\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud\n",
    "from matplotlib.colors import ListedColormap\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
    "import torch\n",
    "from bertopic import BERTopic\n",
    "from umap import UMAP\n",
    "from typing import List, Union\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5644/576945072.py:2: DtypeWarning: Columns (6,7,11,15,16,17,19,30,31,38,39,40,41) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"/media/cattiaux/DATA/Wassati/team_data/schneider/df_labelled.csv\")\n",
      "/tmp/ipykernel_5644/576945072.py:3: DtypeWarning: Columns (7,8,12,16,17,18,20,31,32,39,40,41,42) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df2 = pd.read_csv(\"/media/cattiaux/DATA/Wassati/team_data/schneider/df_sentiment_labelled.csv\")\n",
      "/tmp/ipykernel_5644/576945072.py:4: DtypeWarning: Columns (8,9,13,17,18,19,21,32,33,40,41,42,43) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df3 = pd.read_csv(\"/media/cattiaux/DATA/Wassati/team_data/schneider/df_emotions_labelled.csv\")\n",
      "/tmp/ipykernel_5644/576945072.py:22: DtypeWarning: Columns (10,11,15,19,20,21,23,34,35,42,43,44,45) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df4 = pd.read_csv(\"/media/cattiaux/DATA/Wassati/team_data/schneider/df_all_labelled.csv\", dtype={'year': str})\n"
     ]
    }
   ],
   "source": [
    "# Read the excel review file\n",
    "df = pd.read_csv(\"/media/cattiaux/DATA/Wassati/team_data/schneider/df_labelled.csv\")\n",
    "df2 = pd.read_csv(\"/media/cattiaux/DATA/Wassati/team_data/schneider/df_sentiment_labelled.csv\")\n",
    "df3 = pd.read_csv(\"/media/cattiaux/DATA/Wassati/team_data/schneider/df_emotions_labelled.csv\")\n",
    "\n",
    "# Create a processed_data to be iso with the preprocessing output from the OOP \n",
    "df3[\"processed_data\"] = df3[\"allComment\"]\n",
    "# Convert the string values in the 'predicted_labels' column into lists\n",
    "df3['predicted_labels'] = df3['predicted_labels'].apply(lambda x: ast.literal_eval(x))\n",
    "# Convert the string values in the 'predicted_scores' column into dictionaries\n",
    "df3['predicted_scores'] = df3['predicted_scores'].apply(lambda x: ast.literal_eval(x))\n",
    "# Convert the string values in the 'predicted_scores' column into dictionaries\n",
    "df3['proba_dict'] = df3['proba_dict'].apply(lambda x: ast.literal_eval(x))\n",
    "# Fill empty values in Market Segment column\n",
    "df3['Market Segment'] = df3['Market Segment'].fillna('Unknown')\n",
    "# Convertir la colonne de date en un objet datetime\n",
    "df3['Response Date'] = pd.to_datetime(df3['Response Date'])\n",
    "# Extraire l'année et le mois et les stocker dans une nouvelle colonne\n",
    "df3['year_month'] = df3['Response Date'].dt.to_period('M').dt.to_timestamp()\n",
    "\n",
    "\n",
    "df4 = pd.read_csv(\"/media/cattiaux/DATA/Wassati/team_data/schneider/df_all_labelled.csv\", dtype={'year': str})\n",
    "# df4['year'] = df4['year'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Analyse de Sentiments simple : positif - négatif - neutre\n",
    "\n",
    "def load_model_huggingface(model_name, task, problem_type=None, **kwargs):\n",
    "    \"\"\"\n",
    "    This function loads a model and tokenizer from a given model name, then creates a pipeline to perform a specified task.\n",
    "\n",
    "    Args:\n",
    "        model_name (str): The name of the model to load.\n",
    "        task (str): The type of task to perform with the pipeline.\n",
    "        problem_type (str): The type of problem to solve (\"multi_label_classification\" for multi-label tasks).\n",
    "        **kwargs: Additional arguments to pass to the pipeline.\n",
    "\n",
    "    Returns:\n",
    "        pipeline: A pipeline configured to perform the specified task with the loaded model and tokenizer.\n",
    "    \"\"\"\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name, problem_type=problem_type)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    classifier = pipeline(task, model=model, tokenizer=tokenizer, **kwargs)\n",
    "    return classifier\n",
    "\n",
    "def add_single_label_predictions(df, predictions, predicted_column_name):\n",
    "    \"\"\"\n",
    "    This function merges the DataFrame of single-label predictions with the original DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The original DataFrame.\n",
    "        predictions (list): The list of predictions. Each prediction is a dictionary containing a 'label' and a 'score'.\n",
    "        predicted_column_name (str): The name of the column to be added to the DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The original DataFrame with added columns for the predicted labels and their scores.\n",
    "    \"\"\"\n",
    "    predicted_df = df\n",
    "    # Convert the predictions to a DataFrame\n",
    "    prediction_results = pd.DataFrame(predictions)\n",
    "    prediction_results.rename(columns={'label': predicted_column_name}, inplace=True)\n",
    "    # # Reset the indices of the DataFrames (if necessary)\n",
    "    # df.reset_index(drop=True, inplace=True)\n",
    "    # prediction_results.reset_index(drop=True, inplace=True)\n",
    "    # Merge the original DataFrame with the prediction results\n",
    "    df_predicted = pd.concat([predicted_df, prediction_results], axis=1)\n",
    "    return df_predicted\n",
    "\n",
    "def add_multi_label_predictions(df, predictions, predicted_column_name):\n",
    "    \"\"\"\n",
    "    This function adds a new column with multi-label predictions to the DataFrame and also adds two more columns for \n",
    "    the best label and its score.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The original DataFrame.\n",
    "        predictions (list): The list of predictions. Each prediction is a list of dictionaries, where each dictionary \n",
    "                            contains a 'label' and a 'score'.\n",
    "        predicted_column_name (str): The name of the column to be added to the DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The original DataFrame with added columns for the predicted labels and their scores, as well as \n",
    "                      columns for the best label and its score.\n",
    "    \"\"\"\n",
    "    predicted_df = df\n",
    "    # Keep the original predictions as they are (a list of dictionaries) and add them to the DataFrame as a new column\n",
    "    predicted_df[predicted_column_name] = predictions\n",
    "    # Add columns for the best label and its score\n",
    "    predicted_df[f'best_{predicted_column_name}'] = predicted_df[predicted_column_name].apply(lambda x: max(x.keys(), key=lambda k: x[k]) if x else None)\n",
    "    predicted_df[f'best_{predicted_column_name}_score'] = predicted_df[predicted_column_name].apply(lambda x: x[max(x.keys(), key=lambda k: x[k])] if x else None)\n",
    "    return predicted_df\n",
    "\n",
    "def make_predictions_df(classifier, df, predicted_column_name):\n",
    "    \"\"\"\n",
    "    This function makes predictions on a DataFrame of documents using a given classifier. It adds the predictions to \n",
    "    the DataFrame as new columns. If the classifier is for single-label classification, it adds one column for the \n",
    "    predicted label and one for the score. If the classifier is for multi-label classification, it adds one column \n",
    "    with a dictionary of label-score pairs for each document, and two additional columns for the best label and its score.\n",
    "\n",
    "    Args:\n",
    "        classifier (pipeline): The Hugging Face pipeline object for making predictions.\n",
    "        df (pd.DataFrame): The DataFrame containing the documents to make predictions on. It must have a 'processed_data' \n",
    "                           column with the preprocessed text of each document.\n",
    "        predicted_column_name (str): The name of the column to be added to the DataFrame for the predictions.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The original DataFrame with added columns for the predictions.\n",
    "    \"\"\"\n",
    "    # Get the list of documents from the DataFrame\n",
    "    docs = df[\"processed_data\"].tolist()\n",
    "    # Get predictions\n",
    "    predictions = classifier(docs)\n",
    "    \n",
    "    # Check if predictions is a list of dictionaries (single-label case)\n",
    "    if isinstance(predictions, list) and isinstance(predictions[0], dict):\n",
    "        df_predicted = add_single_label_predictions(df, predictions, predicted_column_name)\n",
    "    \n",
    "    # Multi-label case\n",
    "    elif isinstance(predictions, list) and isinstance(predictions[0], list):\n",
    "        df_predicted = add_multi_label_predictions(df, predictions, predicted_column_name)\n",
    "\n",
    "    return df_predicted\n",
    "\n",
    "classifier = load_model_huggingface(\"cardiffnlp/twitter-roberta-base-sentiment-latest\", \"text-classification\", max_length=512, truncation=True)\n",
    "predicted_df = make_predictions_df(classifier, df3, 'sentiment_label')\n",
    "\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment-latest\")\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment-latest\")\n",
    "# classifier = pipeline('text-classification', model=model, tokenizer=tokenizer, max_length=512, truncation=True)\n",
    "\n",
    "# predictions = []\n",
    "# for review in [[x] for x in df.allComment.tolist()]:\n",
    "      ## Effectuer une prédiction pour le document en utilisant le classificateur\n",
    "#     prediction = classifier(review)\n",
    "      ## Ajouter la prédiction à la liste des prédictions\n",
    "#     predictions.append(prediction)\n",
    "\n",
    "## Création d'un DataFrame à partir des résultats de prédiction\n",
    "# res = pd.DataFrame([item for sublist in predictions for item in sublist])\n",
    "# df_pred = pd.concat([df, res], axis=1)\n",
    "\n",
    "# The model created a column 'label' to store the prediction, BUT the df already had one column 'label', then :\n",
    "# # Rename the second 'label' column to 'sentiment_label'\n",
    "# cols = df_pred.columns.tolist()\n",
    "# cols[len(cols) - 1 - cols[::-1].index('label')] = 'sentiment_label'\n",
    "# df_pred.columns = cols\n",
    "\n",
    "# df_pred.to_csv(\"/media/cattiaux/DATA/Wassati/team_data/schneider/df_sentiment_labelled.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Analyse de Sentiments approfondie : par 28 émotions\n",
    "\n",
    "# # en multilabel, avec GPU et par batch pour accélerer le traitement\n",
    "\n",
    "# # Check if a CUDA-enabled GPU is available\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# model_name = \"SamLowe/roberta-base-go_emotions\"\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(model_name, problem_type=\"multi_label_classification\", max_length=512)\n",
    "\n",
    "# # Move the model to the GPU\n",
    "# model = model.to(device)\n",
    "\n",
    "# # Set the batch size\n",
    "# batch_size = 2\n",
    "\n",
    "# # Create a list of label names\n",
    "# label_emotions = ['admiration', 'amusement', 'anger', 'annoyance', 'approval', 'caring', 'confusion', 'curiosity', 'desire', 'disappointment', 'disapproval', 'disgust', 'embarrassment', 'excitement', 'fear', 'gratitude', 'grief', 'joy', 'love', 'nervousness', 'optimism', 'pride', 'realization', 'relief', 'remorse', 'sadness', 'surprise','neutral']\n",
    "\n",
    "# # Initialize lists to store the predicted labels and scores\n",
    "# predicted_labels = []\n",
    "# predicted_scores = []\n",
    "\n",
    "# df3 = df2\n",
    "# # Iterate over the rows of the DataFrame in batches\n",
    "# for i in range(0, len(df3), batch_size):\n",
    "#     batch = df3[i:i+batch_size]\n",
    "#     texts = batch['allComment'].tolist()\n",
    "#     inputs = tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    \n",
    "#     # Move the inputs to the GPU\n",
    "#     inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    \n",
    "#     outputs = model(**inputs)\n",
    "#     probs = outputs.logits.sigmoid().detach().cpu().numpy()\n",
    "    \n",
    "#     # Apply a threshold to the probabilities to get the predicted labels\n",
    "#     threshold = 0.5\n",
    "#     labels = [[label_emotions[i] for i, prob in enumerate(prob_row) if prob > threshold] for prob_row in probs]\n",
    "    \n",
    "#     # Store the predicted labels and scores\n",
    "#     predicted_labels.extend(labels)\n",
    "#     scores = [{label_emotions[i]: prob for i, prob in enumerate(prob_row)} for prob_row in probs]\n",
    "#     # predicted_scores.extend(probs.tolist())\n",
    "#     predicted_scores.extend(scores)\n",
    "\n",
    "# # Add the predicted labels and scores as new columns in the DataFrame\n",
    "# df3['predicted_labels'] = predicted_labels\n",
    "# df3['predicted_scores'] = predicted_scores\n",
    "\n",
    "# # Convert the string values in the 'predicted_labels' column into lists\n",
    "# df3['predicted_labels'] = df3['predicted_labels'].apply(lambda x: ast.literal_eval(x))\n",
    "# # Convert the string values in the 'predicted_scores' column into dictionaries\n",
    "# df3['predicted_scores'] = df3['predicted_scores'].apply(lambda x: ast.literal_eval(x))\n",
    "\n",
    "# # df3.to_csv(\"/media/cattiaux/DATA/Wassati/team_data/schneider/df_emotions_labelled.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_dict(input_dict, conversion_type='keys_to_values'):\n",
    "    \"\"\"\n",
    "    This function converts between a key-to-value dictionary and a value-to-keys dictionary.\n",
    "\n",
    "    Args:\n",
    "        input_dict (dict): The input dictionary. If conversion_type is 'keys_to_values', this should be a dictionary where \n",
    "                           the keys are the original keys and the values are the corresponding values. If conversion_type is \n",
    "                           'values_to_keys', this should be a dictionary where the keys are the original values and the values \n",
    "                           are lists of keys for each value.\n",
    "        conversion_type (str): The type of conversion to perform. Can be either 'keys_to_values' or 'values_to_keys'.\n",
    "\n",
    "    Returns:\n",
    "        dict: The converted dictionary. If conversion_type is 'keys_to_values', this will be a dictionary where the keys \n",
    "              are the original values and the values are lists of keys for each value. If conversion_type is 'values_to_keys', \n",
    "              this will be a dictionary where the keys are the original keys and the values are the corresponding values.\n",
    "    \"\"\"\n",
    "    if conversion_type == 'keys_to_values':\n",
    "        output_dict = {}\n",
    "        for key, value in input_dict.items():\n",
    "            if value not in output_dict:\n",
    "                output_dict[value] = []\n",
    "            output_dict[value].append(key)\n",
    "    elif conversion_type == 'values_to_keys':\n",
    "        output_dict = {key: value for value, keys in input_dict.items() for key in keys}\n",
    "    else:\n",
    "        raise ValueError(\"Invalid conversion_type. Must be either 'keys_to_values' or 'values_to_keys'.\")\n",
    "    \n",
    "    return output_dict\n",
    "\n",
    "def add_grouping_column(df, key_column, group_dict, group_column_name):\n",
    "    \"\"\"\n",
    "    This function adds a new column to a DataFrame with the group name of each key.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The original DataFrame.\n",
    "        key_column (str): The name of the column in df that contains the keys.\n",
    "        group_dict (dict): A dictionary where the keys are the original keys and the values are the corresponding group names.\n",
    "        group_column_name (str): The name of the new column to be added to df for the groups.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The original DataFrame with an added column for the groups.\n",
    "    \"\"\"\n",
    "    df[group_column_name] = df[key_column].map(group_dict)\n",
    "    return df\n",
    "\n",
    "# transform the multilabel results from the emotions analysis in single label\n",
    "# Define the groups\n",
    "positive_emotions = ['admiration','approval','gratitude','caring','realization','joy','optimism','love','excitement','amusement','relief']\n",
    "negative_emotions = ['disappointment','disapproval','annoyance','confusion','nervousness','fear','sadness','remorse','disgust','embarrassment','anger']\n",
    "neutral_emotions = ['neutral','desire','surprise','curiosity']\n",
    "# Create a dictionary where the keys are the group names and the values are the lists of labels\n",
    "groups = {\"positive\": positive_emotions, \"negative\": negative_emotions, \"neutral\": neutral_emotions}\n",
    "# Convert the groups to a group_dict\n",
    "group_dict = convert_dict(groups, conversion_type='values_to_keys')\n",
    "\n",
    "# Now you can use group_dict with add_grouping_column\n",
    "df3 = add_grouping_column(df3, \"predicted_label\", group_dict, \"sentiment_from_emotion_label\")\n",
    "\n",
    "# # Create a new column 'single_emotion_label' that contains the label with the highest score\n",
    "# df3['single_emotion_label'] = df3['predicted_scores'].apply(lambda x: max(x, key=x.get))\n",
    "# # Create a new column 'sentiment' that contains the sentiment of the emotion in the 'single_emotion_label' column\n",
    "# df3['single_sentiment_from_emotion'] = df3['single_emotion_label'].apply(lambda x: 'positive' if x in positive_emotions else ('negative' if x in negative_emotions else ('neutral' if x in neutral_emotions else 'unknown')))\n",
    "\n",
    "# df3.to_csv(\"/media/cattiaux/DATA/Wassati/team_data/schneider/df_all_labelled.csv\")\n",
    "\n",
    "# Use the explode() method to transform each element of the list into a row\n",
    "# new_df3 = df3.explode('predicted_labels')\n",
    "# new_df3 = new_df3.rename(columns={'predicted_labels': 'emotion_label'})\n",
    "\n",
    "# Pour retourner au df initial avec une liste de label\n",
    "# Group the rows by the original index and aggregate the 'emotion_label' column into a list\n",
    "# original_df = new_df.groupby(new_df.index).agg({'emotion_label': list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### comparaison entre analyse de sentiment simple et les résultats du single label issus de l'analyse d'émotions\n",
    "\n",
    "# Calculate the total number of rows for each sentiment in the 'sentiment_label' column\n",
    "total_positive = len(df3[df3['sentiment_label'] == 'positive'])\n",
    "total_negative = len(df3[df3['sentiment_label'] == 'negative'])\n",
    "total_neutral = len(df3[df3['sentiment_label'] == 'neutral'])\n",
    "\n",
    "# Calculate the number of matches for each sentiment\n",
    "positive_matches = len(df3[(df3['sentiment_label'] == 'positive') & (df3['single_sentiment_from_emotion'] == 'positive')])\n",
    "negative_matches = len(df3[(df3['sentiment_label'] == 'negative') & (df3['single_sentiment_from_emotion'] == 'negative')])\n",
    "neutral_matches = len(df3[(df3['sentiment_label'] == 'neutral') & (df3['single_sentiment_from_emotion'] == 'neutral')])\n",
    "\n",
    "# Calculate the percentage of matches for each sentiment\n",
    "positive_match_percent = positive_matches / total_positive * 100 if total_positive > 0 else 0\n",
    "negative_match_percent = negative_matches / total_negative * 100 if total_negative > 0 else 0\n",
    "neutral_match_percent = neutral_matches / total_neutral * 100 if total_neutral > 0 else 0\n",
    "\n",
    "# Calculate the number of differences for each sentiment\n",
    "positive_differences = total_positive - positive_matches\n",
    "negative_differences = total_negative - negative_matches\n",
    "neutral_differences = total_neutral - neutral_matches\n",
    "\n",
    "# Calculate the percentage of differences for each sentiment\n",
    "positive_difference_percent = positive_differences / total_positive * 100 if total_positive > 0 else 0\n",
    "negative_difference_percent = negative_differences / total_negative * 100 if total_negative > 0 else 0\n",
    "neutral_difference_percent = neutral_differences / total_neutral * 100 if total_neutral > 0 else 0\n",
    "\n",
    "# Calculate the distribution of differences for each sentiment\n",
    "positive_to_negative = len(df3[(df3['sentiment_label'] == 'positive') & (df3['single_sentiment_from_emotion'] == 'negative')])\n",
    "positive_to_neutral = len(df3[(df3['sentiment_label'] == 'positive') & (df3['single_sentiment_from_emotion'] == 'neutral')])\n",
    "negative_to_positive = len(df3[(df3['sentiment_label'] == 'negative') & (df3['single_sentiment_from_emotion'] == 'positive')])\n",
    "negative_to_neutral = len(df3[(df3['sentiment_label'] == 'negative') & (df3['single_sentiment_from_emotion'] == 'neutral')])\n",
    "neutral_to_positive = len(df3[(df3['sentiment_label'] == 'neutral') & (df3['single_sentiment_from_emotion'] == 'positive')])\n",
    "neutral_to_negative = len(df3[(df3['sentiment_label'] == 'neutral') & (df3['single_sentiment_from_emotion'] == 'negative')])\n",
    "\n",
    "# Print the results\n",
    "print(f\"Positive matches: {positive_match_percent:.2f}%\")\n",
    "print(f\"Negative matches: {negative_match_percent:.2f}%\")\n",
    "print(f\"Neutral matches: {neutral_match_percent:.2f}%\")\n",
    "print(f\"Positive differences: {positive_difference_percent:.2f}%\")\n",
    "print(f\"Negative differences: {negative_difference_percent:.2f}%\")\n",
    "print(f\"Neutral differences: {neutral_difference_percent:.2f}%\")\n",
    "print(f\"Positive to Negative: {positive_to_negative / total_positive * 100:.2f}%\" if total_positive > 0 else \"Positive to Negative: N/A\")\n",
    "print(f\"Positive to Neutral: {positive_to_neutral / total_positive * 100:.2f}%\" if total_positive > 0 else \"Positive to Neutral: N/A\")\n",
    "print(f\"Negative to Positive: {negative_to_positive / total_negative * 100:.2f}%\" if total_negative > 0 else \"Negative to Positive: N/A\")\n",
    "print(f\"Negative to Neutral: {negative_to_neutral / total_negative * 100:.2f}%\" if total_negative > 0 else \"Negative to Neutral: N/A\")\n",
    "print(f\"Neutral to Positive: {neutral_to_positive / total_neutral * 100:.2f}%\" if total_neutral > 0 else \"Neutral to Positive: N/A\")\n",
    "print(f\"Neutral to Negative: {neutral_to_negative / total_neutral * 100:.2f}%\" if total_neutral > 0 else \"Neutral to Negative: N/A\")\n",
    "\n",
    "# Filter the DataFrame to only include rows where the 'sentiment_label' is 'negative' and the 'single_sentiment_label' is 'neutral'\n",
    "negative_to_neutral = df3[(df3['sentiment_label'] == 'negative') & (df3['single_sentiment_from_emotion'] == 'neutral')]\n",
    "\n",
    "# Calculate the distribution of emotions in the 'single_emotion_label' column\n",
    "emotion_distribution = negative_to_neutral['single_emotion_label'].value_counts(normalize=True) * 100\n",
    "\n",
    "# Print the results\n",
    "emotion_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### chargement du model bertopic\n",
    "\n",
    "def load_bertopic_model(filename):\n",
    "    \"\"\"\n",
    "    Load a BERTopic model and associated data from a file.\n",
    "    \n",
    "    :param filename: The name of the file to load the data from.\n",
    "    :return: A tuple containing the loaded BERTopic model, topics, probs, and docs variables.\n",
    "    \"\"\"\n",
    "    # Load the BERTopic model\n",
    "    topic_model = BERTopic.load(filename)\n",
    "    \n",
    "    # Load the topics, probs, and docs variables\n",
    "    with open(filename + '_data.pkl', 'rb') as f:\n",
    "        topics, probs, embeddings, docs = pickle.load(f)\n",
    "    \n",
    "    return topic_model, topics, probs, embeddings, docs\n",
    "\n",
    "topic_model, topics, probs, embeddings, docs = load_bertopic_model('../models/raw_keybert_bertopic_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cattiaux/anaconda3/envs/wassati/lib/python3.9/site-packages/bertopic/vectorizers/_ctfidf.py:69: RuntimeWarning: divide by zero encountered in divide\n",
      "  idf = np.log((avg_nr_samples / df)+1)\n"
     ]
    }
   ],
   "source": [
    "def create_merged_model(docs, bertopic_model, topics_to_merge_dict, label_names_dict):\n",
    "    \"\"\"\n",
    "    Create a new BERTopic model by merging topics from an existing model.\n",
    "\n",
    "    This function takes as input a list of documents `docs`, an existing BERTopic model `bertopic_model`, a dictionary `topics_to_merge_dict` specifying which topics to merge, and a dictionary `label_names_dict` specifying the labels for the merged topics.\n",
    "\n",
    "    The function creates a deep copy of the input BERTopic model and merges the specified topics using the `merge_topics` method. Then, it sets the topic labels for the merged model using the `set_topic_labels` method and the provided `label_names_dict`.\n",
    "\n",
    "    The resulting merged BERTopic model is then returned.\n",
    "\n",
    "    Parameters:\n",
    "        docs (list): A list of documents used to fit the BERTopic model.\n",
    "        bertopic_model (BERTopic): The input BERTopic model to be merged.\n",
    "        topics_to_merge_dict (dict): A dictionary specifying which topics to merge. The keys are the topic numbers to be merged, and the values are the topic numbers into which they should be merged.\n",
    "        label_names_dict (dict): A dictionary specifying the labels for the merged topics. The keys are the topic numbers, and the values are the corresponding labels.\n",
    "\n",
    "    Returns:\n",
    "        BERTopic: The resulting merged BERTopic model.\n",
    "    \"\"\"\n",
    "    topic_model_merged = copy.deepcopy(bertopic_model)\n",
    "    topic_model_merged.merge_topics(docs, topics_to_merge_dict)\n",
    "\n",
    "    # Create a dictionary to match the aggregated name to their corresponding topic number\n",
    "    mergedtopic_labels_dict = {i-1: item for i, item in enumerate(label_names_dict)}\n",
    "    # Set topic labels for the aggregated model\n",
    "    topic_model_merged.set_topic_labels(mergedtopic_labels_dict)\n",
    "\n",
    "    return topic_model_merged### Création du modèle bertopic aggrégé pour topics finaux\n",
    "\n",
    "# List of topics numbers. Each value of this list is a list that contains the topic number of the topics to join together\n",
    "topics_to_merge = [ [42,3,0,13], #Delivery Deadlines : challenges and strategies involved in managing delivery deadlines in logistics operations. (vert)\n",
    "                    [20,50,27], #Quotation and Pricing Strategies (vert bas)\n",
    "                    [35,32], #Touch Panels and Screens (rouge, haut)\n",
    "                    [40,36], #Frequency Converters : frequency converters used in industrial applications and the technical support provided by manufacturers and suppliers (rouge, suite)\n",
    "                    [37,21,6,12,9,4,1,14,16,31,19], #“Automation Components” : hardware and software components used in industrial automation systems. (rouge centre)\n",
    "                    [33,46,8], #Product Evaluation : evaluate the quality, affordability and reliability of products and services (rouge, fin)\n",
    "                    [44,51,23,41,49,57,22], #Customer Support : Reliability and Quality in Customer Service and Support (bleu ciel)\n",
    "                    [58,59], #Quick Customer Service (marron)\n",
    "                    [38,10,26,52,39,43], #Problem Solving and Communication (focus on the importance of being efficient and precise when solving problems) (jaune)\n",
    "                    [45,47,55,53,54], #Assistance and Guidance (noir)\n",
    "                    [29,30,11,24], #Power Supply Issues (2e vert, haut)\n",
    "                    [7,5,2,25,15,34,18,28,17], #Technical Support (2e vert, bas)\n",
    "                    [48,56] #None : positive feedback (2e rouge)\n",
    "]\n",
    "\n",
    "# Set the topic names for the new aggregated topic\n",
    "# It must match the order from the topics_to_merge list\n",
    "label_names = [\n",
    "    \"Outliers\",\n",
    "    \"Automation Components\",\n",
    "    \"Technical Support\",\n",
    "    \"Delivery Deadlines\",\n",
    "    \"Problem Solving & Comm\",\n",
    "    \"Power Supply Issues\",\n",
    "    \"Customer Support\", #Reliability and Quality in Customer Service and Support\n",
    "    \"Product Evaluation\",\n",
    "    \"Pricing\", #Quotation and Pricing Strategies\n",
    "    \"Assistance\", #Assistance and Guidance\n",
    "    \"Touch Screens\", #Touch Panels and Screens\n",
    "    \"Frequency Converters\",\n",
    "    \"Positive feedback\",\n",
    "    \"Quick Customer Service\"\n",
    "    ]\n",
    "\n",
    "# Create a new merged bertopic model \n",
    "topic_model_merged = create_merged_model(docs, topic_model, topics_to_merge, label_names)\n",
    "# topic_model_merged.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Modify the visualize_topics_per_class method from bertopic to be able to print a barchart vertically\n",
    "# def visualize_topics_per_class_orient(topic_model,\n",
    "#                                topics_per_class: pd.DataFrame,\n",
    "#                                top_n_topics: int = 10,\n",
    "#                                topics: List[int] = None,\n",
    "#                                normalize_frequency: bool = False,\n",
    "#                                custom_labels: Union[bool, str] = False,\n",
    "#                                title: str = \"<b>Topics per Class</b>\",\n",
    "#                                width: int = 1250,\n",
    "#                                height: int = 900,\n",
    "#                                orient: str = \"h\") -> go.Figure:\n",
    "#     \"\"\" Visualize topics per class\n",
    "\n",
    "#     Arguments:\n",
    "#         topic_model: A fitted BERTopic instance.\n",
    "#         topics_per_class: The topics you would like to be visualized with the\n",
    "#                           corresponding topic representation\n",
    "#         top_n_topics: To visualize the most frequent topics instead of all\n",
    "#         topics: Select which topics you would like to be visualized\n",
    "#         normalize_frequency: Whether to normalize each topic's frequency individually\n",
    "#         custom_labels: If bool, whether to use custom topic labels that were defined using \n",
    "#                        `topic_model.set_topic_labels`.\n",
    "#                        If `str`, it uses labels from other aspects, e.g., \"Aspect1\".\n",
    "#         title: Title of the plot.\n",
    "#         width: The width of the figure.\n",
    "#         height: The height of the figure.\n",
    "#         orient: The orientation of the barchart, 'h' for horizontal, anything else for vertical\n",
    "\n",
    "#     Returns:\n",
    "#         A plotly.graph_objects.Figure including all traces\n",
    "\n",
    "#     Examples:\n",
    "\n",
    "#     To visualize the topics per class, simply run:\n",
    "\n",
    "#     ```python\n",
    "#     topics_per_class = topic_model.topics_per_class(docs, classes)\n",
    "#     topic_model.visualize_topics_per_class(topics_per_class)\n",
    "#     ```\n",
    "\n",
    "#     Or if you want to save the resulting figure:\n",
    "\n",
    "#     ```python\n",
    "#     fig = topic_model.visualize_topics_per_class(topics_per_class)\n",
    "#     fig.write_html(\"path/to/file.html\")\n",
    "#     ```\n",
    "#     <iframe src=\"../../getting_started/visualization/topics_per_class.html\"\n",
    "#     style=\"width:1400px; height: 1000px; border: 0px;\"\"></iframe>\n",
    "#     \"\"\"\n",
    "#     colors = [\"#E69F00\", \"#56B4E9\", \"#009E73\", \"#F0E442\", \"#D55E00\", \"#0072B2\", \"#CC79A7\"]\n",
    "\n",
    "#     # Select topics based on top_n and topics args\n",
    "#     freq_df = topic_model.get_topic_freq()\n",
    "#     freq_df = freq_df.loc[freq_df.Topic != -1, :]\n",
    "#     if topics is not None:\n",
    "#         selected_topics = list(topics)\n",
    "#     elif top_n_topics is not None:\n",
    "#         selected_topics = sorted(freq_df.Topic.to_list()[:top_n_topics])\n",
    "#     else:\n",
    "#         selected_topics = sorted(freq_df.Topic.to_list())\n",
    "\n",
    "#     # Prepare data\n",
    "#     if isinstance(custom_labels, str):\n",
    "#         topic_names = [[[str(topic), None]] + topic_model.topic_aspects_[custom_labels][topic] for topic in topics]\n",
    "#         topic_names = [\"_\".join([label[0] for label in labels[:4]]) for labels in topic_names]\n",
    "#         topic_names = [label if len(label) < 30 else label[:27] + \"...\" for label in topic_names]\n",
    "#         topic_names = {key: topic_names[index] for index, key in enumerate(topic_model.topic_labels_.keys())}\n",
    "#     elif topic_model.custom_labels_ is not None and custom_labels:\n",
    "#         topic_names = {key: topic_model.custom_labels_[key + topic_model._outliers] for key, _ in topic_model.topic_labels_.items()}\n",
    "#     else:\n",
    "#         topic_names = {key: value[:40] + \"...\" if len(value) > 40 else value\n",
    "#                        for key, value in topic_model.topic_labels_.items()}\n",
    "#     topics_per_class[\"Name\"] = topics_per_class.Topic.map(topic_names)\n",
    "#     data = topics_per_class.loc[topics_per_class.Topic.isin(selected_topics), :]\n",
    "\n",
    "#     # Add traces\n",
    "#     fig = go.Figure()\n",
    "#     for index, topic in enumerate(selected_topics):\n",
    "#         if index == 0:\n",
    "#             visible = True\n",
    "#         else:\n",
    "#             visible = \"legendonly\"\n",
    "#         trace_data = data.loc[data.Topic == topic, :]\n",
    "#         topic_name = trace_data.Name.values[0]\n",
    "#         words = trace_data.Words.values\n",
    "#         if normalize_frequency:\n",
    "#             x = normalize(trace_data.Frequency.values.reshape(1, -1))[0]\n",
    "#         else:\n",
    "#             x = trace_data.Frequency\n",
    "\n",
    "#         ### Old part from the source github of bertopic ###\n",
    "#         # fig.add_trace(go.Bar(y=trace_data.Class,\n",
    "#         #                      x=x,\n",
    "#         #                      visible=visible,\n",
    "#         #                      marker_color=colors[index % 7],\n",
    "#         #                      hoverinfo=\"text\",\n",
    "#         #                      name=topic_name,\n",
    "#         #                      orientation=\"h\",\n",
    "#         #                      hovertext=[f'<b>Topic {topic}</b><br>Words: {word}' for word in words]))\n",
    "        \n",
    "#         fig.add_trace(go.Bar(y=trace_data.Class if orient == \"h\" else x,\n",
    "#                             x=x if orient == \"h\" else trace_data.Class,\n",
    "#                             visible=visible,\n",
    "#                             marker_color=colors[index % 7],\n",
    "#                             hoverinfo=\"text\",\n",
    "#                             name=topic_name,\n",
    "#                             orientation=orient,\n",
    "#                             hovertext=[f'<b>Topic {topic}</b><br>Words: {word}' for word in words]))\n",
    "\n",
    "#     # Styling of the visualization\n",
    "#     fig.update_xaxes(showgrid=True)\n",
    "#     fig.update_yaxes(showgrid=True)\n",
    "#     fig.update_layout(\n",
    "#         xaxis_title=\"Normalized Frequency\" if normalize_frequency else \"Frequency\",\n",
    "#         yaxis_title=\"Class\",\n",
    "#         title={\n",
    "#             'text': f\"{title}\",\n",
    "#             'y': .95,\n",
    "#             'x': 0.40,\n",
    "#             'xanchor': 'center',\n",
    "#             'yanchor': 'top',\n",
    "#             'font': dict(\n",
    "#                 size=22,\n",
    "#                 color=\"Black\")\n",
    "#         },\n",
    "#         template=\"simple_white\",\n",
    "#         width=width,\n",
    "#         height=height,\n",
    "#         hoverlabel=dict(\n",
    "#             bgcolor=\"white\",\n",
    "#             font_size=16,\n",
    "#             font_family=\"Rockwell\"\n",
    "#         ),\n",
    "#         legend=dict(\n",
    "#             title=\"<b>Global Topic Representation\",\n",
    "#         )\n",
    "#     )\n",
    "#     return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_percentage_old(df, topic_col='Topic', freq_col='Frequency', class_col=None, group_by=None):\n",
    "    \"\"\"\n",
    "    This function adds a percentage column to a dataframe. The percentage is calculated as the frequency of each topic within each class.\n",
    "    \n",
    "    Parameters:\n",
    "    df (DataFrame): The input dataframe.\n",
    "    topic_col (str, optional): The name of the topic column in the dataframe. Defaults to 'Topic'.\n",
    "    freq_col (str, optional): The name of the frequency column in the dataframe. Defaults to 'Frequency'.\n",
    "    class_col (str, optional): The name of the class column in the dataframe. If specified, the function will calculate the percentage for each topic within each class. Defaults to None.\n",
    "    group_by (str, optional): Specifies whether to group by 'topic' or 'class'. Defaults to 'topic' if class_col is None, else defaults to 'class'.\n",
    "\n",
    "    Returns:\n",
    "    DataFrame: A dataframe with an added 'Percentage' column.\n",
    "    \n",
    "    Raises:\n",
    "    ValueError: If `group_by` is not 'topic' or 'class'.\n",
    "    \"\"\"\n",
    "    if group_by is None:\n",
    "        group_by = 'Topic' if class_col is None else 'Class'\n",
    "        \n",
    "    if group_by not in ['Topic', 'Class']:\n",
    "        raise ValueError(\"`group_by` should be either 'Topic' or 'Class'\")\n",
    "        \n",
    "    # Check if columns exist in dataframe\n",
    "    for col in [col for col in [topic_col, class_col, freq_col] if col is not None]:\n",
    "        if col not in df.columns:\n",
    "            print(f\"Warning: Column '{col}' not found in dataframe. The function will proceed with default column names.\")\n",
    "\n",
    "    # Calculate the total frequency per group\n",
    "    if group_by == 'Topic' or class_col is None:\n",
    "        df_total = df.groupby(topic_col)[freq_col].sum().reset_index()\n",
    "    else:  # group_by == 'Class'\n",
    "        df_total = df.groupby(class_col)[freq_col].sum().reset_index()\n",
    "        \n",
    "    df_total.columns = [group_by, 'Total']\n",
    "\n",
    "    # Merge these two dataframes\n",
    "    df_merged = pd.merge(df, df_total, on=group_by)\n",
    "    # Calculate the percentage and round to 2 decimal places\n",
    "    df_merged['Percentage'] = (df_merged[freq_col] / df_merged['Total'] * 100).round(2)\n",
    "    \n",
    "    # Replace NaN values with 0\n",
    "    df_merged['Percentage'].fillna(0, inplace=True)\n",
    "    # Drop the 'Total' column\n",
    "    df_merged.drop(columns=['Total'], inplace=True)\n",
    "\n",
    "    return df_merged\n",
    "\n",
    "def add_percentage(df, topic_col='Topic', freq_col='Frequency', include_outliers=False):\n",
    "    \"\"\"\n",
    "    This function adds two percentage columns to a dataframe. The first percentage is calculated as the frequency of each topic within each class. The second percentage is calculated as the frequency of each class within each topic.\n",
    "    \n",
    "    Parameters:\n",
    "    df (DataFrame): The input dataframe.\n",
    "    topic_col (str, optional): The name of the topic column in the dataframe. Defaults to 'Topic'.\n",
    "    freq_col (str, optional): The name of the frequency column in the dataframe. Defaults to 'Frequency'.\n",
    "    include_outliers (bool, optional): Whether to include outliers (topic number -1) in the percentage computation. Defaults to True.\n",
    "\n",
    "    Returns:\n",
    "    DataFrame: A dataframe with added 'Topic_Percentage' and 'Class_Percentage' columns.\n",
    "    \"\"\" \n",
    "    # If not including outliers, remove them from the dataframe\n",
    "    if not include_outliers:\n",
    "        df = df[df[topic_col] != -1]\n",
    "\n",
    "    # Check if columns exist in dataframe\n",
    "    for col in [col for col in [topic_col, freq_col] if col is not None]:\n",
    "        if col not in df.columns:\n",
    "            print(f\"Warning: Column '{col}' not found in dataframe. The function will proceed with default column names.\")\n",
    "\n",
    "    # Calculate the total frequency per topic\n",
    "    df_total_topic = df.groupby(topic_col)[freq_col].sum().reset_index()\n",
    "    df_total_topic.columns = [topic_col, 'Total_Topic']\n",
    "\n",
    "    # Calculate the total frequency per class\n",
    "    df_total_class = df.groupby(\"Class\")[freq_col].sum().reset_index()\n",
    "    df_total_class.columns = [\"Class\", 'Total_Class']\n",
    "\n",
    "    # Merge these two dataframes with original dataframe\n",
    "    df_merged = pd.merge(df, df_total_topic, on=topic_col)\n",
    "    df_merged = pd.merge(df_merged, df_total_class, on=\"Class\")\n",
    "\n",
    "    # Calculate the percentages and round to 2 decimal places\n",
    "    df_merged['Topic_Percentage'] = (df_merged[freq_col] / df_merged['Total_Topic'] * 100).round(2)\n",
    "    df_merged['Class_Percentage'] = (df_merged[freq_col] / df_merged['Total_Class'] * 100).round(2)\n",
    "    \n",
    "    # Replace NaN values with 0\n",
    "    df_merged['Topic_Percentage'].fillna(0, inplace=True)\n",
    "    df_merged['Class_Percentage'].fillna(0, inplace=True)\n",
    "\n",
    "    # Drop the 'Total' columns\n",
    "    df_merged.drop(columns=['Total_Topic', 'Total_Class'], inplace=True)\n",
    "\n",
    "    return df_merged\n",
    "\n",
    "def add_customLabelCol(df, bertopic_model):\n",
    "    \"\"\"\n",
    "    This function adds a new column 'Name' to the input DataFrame 'df' based on the custom labels \n",
    "    from the BERTopic model 'bertopic_model'. The new column 'Name' is mapped from the 'Topic' \n",
    "    column of the DataFrame using the custom labels.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): The input DataFrame to which the new column will be added.\n",
    "    bertopic_model (BERTopic): The BERTopic model which contains the custom labels.\n",
    "\n",
    "    Returns:\n",
    "    new_df (pandas.DataFrame): The DataFrame with the added 'Name' column.\n",
    "    \"\"\"\n",
    "    new_df=df\n",
    "    custom_labels = bertopic_model.custom_labels_\n",
    "    custom_labels_dict = {i-1: label for i, label in enumerate(custom_labels)}\n",
    "    # Add a new column 'Custom_Label' to the DataFrame\n",
    "    new_df['Name'] = new_df['Topic'].map(custom_labels_dict)\n",
    "    return new_df\n",
    "\n",
    "def old_create_topics_per_class_df(df, bertopic_model, classes_column, filter=False, filter_group=None, filter_value=None,  sortedBy=None, ascending=True):\n",
    "    \"\"\"\n",
    "    Create a dataframe representing the topics per class.\n",
    "\n",
    "    This function takes as input a dataframe `df`, a BERTopic model `bertopic_model`, a column name `classes_column` representing the classes, an optional boolean parameter `filter` which determines whether to filter the data based on a subclass, an optional parameter `filter_group` representing the column name of the subclass to filter on, an optional parameter `filter_value` representing the value of the subclass to filter on, an optional parameter `sortedBy` which can be used to sort the topics by either \"Frequency\" or \"Name\", and an optional boolean parameter `ascending` which determines the sorting order (ascending or descending).\n",
    "\n",
    "    The function first checks that the values of `sortedBy`, `ascending`, and `subclass_name` and `subclass_value` (if `filter` is `True`) are valid. If any of these values are not valid, a ValueError is raised with an appropriate error message.\n",
    "\n",
    "    Then, depending on whether `filter` is `True` or not, the function either calculates the topics per class using the `topics_per_class` method of the BERTopic model or calls a nested function `topics_per_subclass` to compute the topics per class with filtering. It also adds a percentage column to the topics_per_class dataframe using add_percentage() method. The percentage is calculated as the frequency of each class within each topic.\n",
    "\n",
    "    If `sortedBy` is \"Frequency\", the resulting dataframe is sorted by frequency in either ascending or descending order depending on the value of `ascending`.\n",
    "\n",
    "    The resulting dataframe is then returned.\n",
    "\n",
    "    Parameters:\n",
    "        df (pandas.DataFrame): The input dataframe containing the data to be used.\n",
    "        bertopic_model (BERTopic): The BERTopic model used to calculate the topics per class.\n",
    "        classes_column (str): The name of the column in `df` representing the classes.\n",
    "        filter (bool): An optional boolean parameter used to determine whether to filter the data based on a subclass. Defaults to False.\n",
    "        filter_group (str): An optional parameter representing the column name of the subclass to filter on. Only used if `filter` is True. Defaults to None.\n",
    "        filter_value: An optional parameter representing the value of the subclass to filter on. Only used if `filter` is True. Defaults to None.\n",
    "        sortedBy (str): An optional parameter used to sort the topics by either \"Frequency\" or \"Name\". Defaults to None.\n",
    "        ascending (bool): An optional boolean parameter used to determine the sorting order. If True, sorts in ascending order. If False, sorts in descending order. Defaults to True.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: A dataframe representing the topics per class.\n",
    "    \"\"\"\n",
    "    # Check that the value of sortedBy is valid\n",
    "    if sortedBy not in [None, \"Frequency\", \"Class\", \"Topic_Percentage\", \"Class_Percentage\"]:\n",
    "        raise ValueError(\"sortedBy must be either None (default value), 'Frequency',  'Class', 'Topic_Percentage' or 'Class_Percentage'\")\n",
    "    # Check that ascending is only used if sortedBy is not None\n",
    "    if sortedBy is None and ascending != True:\n",
    "        raise ValueError(\"ascending can only be used if sortedBy parameter is used\")\n",
    "    # Check that the value of ascending is valid\n",
    "    if ascending not in [True, False]:\n",
    "        raise ValueError(\"ascending must be either True or False\")\n",
    "    # Check that subclass_name and subclass_value are provided if filter is True\n",
    "    if filter and (filter_group is None or filter_value is None):\n",
    "        raise ValueError(\"If filter is True, both filter_name and filter_value must be provided\")\n",
    "    \n",
    "    df['year'] = df['year'].astype(str)\n",
    "    \n",
    "    # Define a function to compute topics_per_class with filtering\n",
    "    def topics_per_subclass():\n",
    "        \"\"\"\n",
    "        Create a dataframe that contains the topic number, the list of words that describe the topic,\n",
    "        and the frequency of documents from this topic that belong to the element from the first \"Class\" column\n",
    "        for a subset of data that is filtered by a given subclass value.\n",
    "        Basically it does the same as topics_per_class method from bertopic adding a filter that depends on an other class\n",
    "\n",
    "        :param df: A pandas DataFrame containing the full data\n",
    "        :param bertopic_model: A bertopic model used to compute the topics\n",
    "        :param classes_column: The name of the column in df that contains the class values\n",
    "        :param filter_group: The name of the column in df that contains the subclass values (the filter values)\n",
    "        :param filter_value: The value of the subclass to filter the data by\n",
    "        :return: A pandas DataFrame containing the topic number, the list of words that describe the topic,\n",
    "                and the frequency of documents from this topic that belong to the element from the first \"Class\" column\n",
    "                for the filtered data (subclass data)\n",
    "        \"\"\"\n",
    "        # Filter your data based on the values from the chosen subclass\n",
    "        filtered_data = df[df[filter_group] == filter_value]\n",
    "        classes_filtered_data=filtered_data[classes_column].astype(str).tolist()\n",
    "        filtered_topics = [bertopic_model.topics_[i] for i in filtered_data.index.tolist()]\n",
    "\n",
    "        # Create manually a topic_per_class dataframe from a subset of the full documents\n",
    "        topics_per_subClass_df = pd.DataFrame({'Topic': filtered_topics, 'Class': classes_filtered_data})\n",
    "        # Calculate the frequency of each topic for each class\n",
    "        topics_per_subClass_df = topics_per_subClass_df.groupby(['Topic', 'Class']).size().reset_index(name='Frequency')\n",
    "        # Add the words that describe each topic\n",
    "        topic_words = {row['Topic']: row['Name'] for _, row in bertopic_model.get_topic_info().iterrows()}\n",
    "        topics_per_subClass_df['Words'] = topics_per_subClass_df['Topic'].map(topic_words)\n",
    "\n",
    "        # Add rows for missing topics with a frequency of 0\n",
    "        missing_topics = set(bertopic_model.get_topics().keys()) - set(topics_per_subClass_df['Topic'].unique())\n",
    "        for topic in missing_topics:\n",
    "            for class_ in topics_per_subClass_df['Class'].unique():\n",
    "                new_row = pd.DataFrame({\n",
    "                    'Topic': [topic],\n",
    "                    'Words': [topic_words[topic]],\n",
    "                    'Frequency': [0],\n",
    "                    'Class': [class_]\n",
    "                })\n",
    "                topics_per_subClass_df = pd.concat([topics_per_subClass_df, new_row], ignore_index=True)\n",
    "        \n",
    "        return topics_per_subClass_df\n",
    "\n",
    "    # Define a function to compute topics_per_class with filtering\n",
    "    def topics_per_subclass_new():\n",
    "        \"\"\"\n",
    "        Create a dataframe that contains the topic number, the list of words that describe the topic,\n",
    "        and the frequency of documents from this topic that belong to the element from the first \"Class\" column\n",
    "        for a subset of data that is filtered by a given subclass value.\n",
    "        Basically it does the same as topics_per_class method from bertopic adding a filter that depends on an other class\n",
    "\n",
    "        :param df: A pandas DataFrame containing the full data\n",
    "        :param bertopic_model: A bertopic model used to compute the topics\n",
    "        :param classes_column: The name of the column in df that contains the class values\n",
    "        :param filter_group: The name of the column in df that contains the subclass values (the filter values)\n",
    "        :param filter_value: The value of the subclass to filter the data by\n",
    "        :return: A pandas DataFrame containing the topic number, the list of words that describe the topic,\n",
    "                and the frequency of documents from this topic that belong to the element from the first \"Class\" column\n",
    "                for the filtered data (subclass data)\n",
    "        \"\"\"\n",
    "        topics_per_class = bertopic_model.topics_per_class(df[\"processed_data\"].astype(str).tolist(), classes=df[classes_column].to_list())\n",
    "        topics_per_class = add_percentage(topics_per_class, topic_col='Topic', freq_col='Frequency')\n",
    "        # Filter your data based on the values from the chosen subclass\n",
    "        topics_per_subClass_df = topics_per_class[topics_per_class['Class'] == filter_value]\n",
    "\n",
    "        # Add rows for missing topics with a frequency of 0\n",
    "        topic_words = {row['Topic']: row['Name'] for _, row in bertopic_model.get_topic_info().iterrows()}\n",
    "        # missing_topics = set(bertopic_model.get_topics().keys()) - set(topics_per_subClass_df['Topic'].unique())\n",
    "        missing_topics = {topic for topic in bertopic_model.get_topics().keys() if topic != -1} - set(topics_per_subClass_df['Topic'].unique())\n",
    "        for topic in missing_topics:\n",
    "            for class_ in topics_per_subClass_df['Class'].unique():\n",
    "                new_row = pd.DataFrame({\n",
    "                    'Topic': [topic],\n",
    "                    'Words': [topic_words[topic]],\n",
    "                    'Frequency': [0],\n",
    "                    'Topic_Percentage': [0],\n",
    "                    'Class_Percentage': [0],\n",
    "                    'Class': [class_]\n",
    "                })\n",
    "                topics_per_subClass_df = pd.concat([topics_per_subClass_df, new_row], ignore_index=True)\n",
    "        \n",
    "        return topics_per_subClass_df\n",
    "\n",
    "    if filter:\n",
    "        topics_per_class = topics_per_subclass_new()\n",
    "    else:\n",
    "        topics_per_class = bertopic_model.topics_per_class(df[\"processed_data\"].astype(str).tolist(), classes=df[classes_column].to_list())\n",
    "        # Add percentage columns to dataframe\n",
    "        topics_per_class = add_percentage(topics_per_class, topic_col='Topic', freq_col='Frequency')\n",
    "\n",
    "    # Check if there are existing custom_labels names in the bertopic model and add them in a column if there are some\n",
    "    if bertopic_model.custom_labels_ is not None :\n",
    "        topics_per_class = add_customLabelCol(topics_per_class, bertopic_model)\n",
    "\n",
    "    if sortedBy:\n",
    "        topics_per_class = topics_per_class.sort_values(by=sortedBy, ascending=ascending)\n",
    "    \n",
    "    return topics_per_class\n",
    "\n",
    "def create_topics_per_class_df(df, bertopic_model, classes_column, filter_value=None,  sortedBy=None, ascending=True):\n",
    "    \"\"\"\n",
    "    Computes the distribution of topics per class in the given DataFrame. Optionally filters the data by a given subclass and sorts the resulting DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): The input DataFrame.\n",
    "    bertopic_model (BERTopic): The BERTopic model used to compute the topics.\n",
    "    classes_column (str): The name of the column in df that contains the class values.\n",
    "    filter_value (str, optional): The value of the subclass to filter the data by. Required if filter is True.\n",
    "    sortedBy (str, optional): Column name to sort by. Must be either None (default), 'Frequency', 'Class', 'Topic_Percentage' or 'Class_Percentage'.\n",
    "    ascending (bool, optional): Whether to sort in ascending order. Default is True. Can only be used if sortedBy is not None.\n",
    "\n",
    "    Returns:\n",
    "    pandas.DataFrame: A DataFrame containing the topic number, the list of words that describe the topic, and the frequency and percentage of documents from this topic that belong to each class.\n",
    "    \"\"\"\n",
    "    # Check that the value of sortedBy is valid\n",
    "    if sortedBy not in [None, \"Frequency\", \"Class\", \"Topic_Percentage\", \"Class_Percentage\"]:\n",
    "        raise ValueError(\"sortedBy must be either None (default value), 'Frequency',  'Class', 'Topic_Percentage' or 'Class_Percentage'\")\n",
    "    # Check that ascending is only used if sortedBy is not None\n",
    "    if sortedBy is None and ascending != True:\n",
    "        raise ValueError(\"ascending can only be used if sortedBy parameter is used\")\n",
    "    # Check that the value of ascending is valid\n",
    "    if ascending not in [True, False]:\n",
    "        raise ValueError(\"ascending must be either True or False\")\n",
    "    \n",
    "    # Compute topics_per_class dataframe using bertopic method\n",
    "    topics_per_class = bertopic_model.topics_per_class(df[\"processed_data\"].astype(str).tolist(), classes=df[classes_column].to_list())\n",
    "    # Add percentage columns to dataframe\n",
    "    topics_per_class = add_percentage(topics_per_class, topic_col='Topic', freq_col='Frequency')\n",
    "\n",
    "    if filter_value : \n",
    "        # Filter your data based on the values from the chosen subclass\n",
    "        topics_per_class = topics_per_class[topics_per_class['Class'] == filter_value]\n",
    "\n",
    "        # Add rows for missing topics with a frequency of 0\n",
    "        topic_words = {row['Topic']: row['Name'] for _, row in bertopic_model.get_topic_info().iterrows()}\n",
    "        missing_topics = {topic for topic in bertopic_model.get_topics().keys() if topic != -1} - set(topics_per_class['Topic'].unique())\n",
    "        for topic in missing_topics:\n",
    "            for class_ in topics_per_class['Class'].unique():\n",
    "                new_row = pd.DataFrame({\n",
    "                    'Topic': [topic],\n",
    "                    'Words': [topic_words[topic]],\n",
    "                    'Frequency': [0],\n",
    "                    'Topic_Percentage': [0],\n",
    "                    'Class_Percentage': [0],\n",
    "                    'Class': [class_]\n",
    "                })\n",
    "                topics_per_class = pd.concat([topics_per_class, new_row], ignore_index=True)\n",
    "\n",
    "    # Check if there are existing custom_labels names in the bertopic model and add them in a column if there are some\n",
    "    if bertopic_model.custom_labels_ is not None :\n",
    "        topics_per_class = add_customLabelCol(topics_per_class, bertopic_model)\n",
    "    # Sort the dataframe to prepare the visualization\n",
    "    if sortedBy:\n",
    "        topics_per_class = topics_per_class.sort_values(by=sortedBy, ascending=ascending)\n",
    "    \n",
    "    return topics_per_class\n",
    "\n",
    "def visualize_topics_per_class_options(topic_model, topics_per_class, orient=\"h\", percentage_by=None, viz_from_source=False, stacked=False, **kwargs):\n",
    "    \"\"\"\n",
    "    Visualizes the distribution of topics per class with additional options for orientation and percentage usage.\n",
    "\n",
    "    Parameters:\n",
    "    topic_model : The trained BERTopic model.\n",
    "    topics_per_class : A DataFrame containing the topics per class.\n",
    "    orient (str, optional): The orientation of the plot. Defaults to \"h\".\n",
    "    use_percentage (bool, optional): Whether to use percentage for the representation of the data. Defaults to False.\n",
    "    **kwargs: Arbitrary keyword arguments for the visualize_topics_per_class_orient function.\n",
    "\n",
    "    Returns:\n",
    "    go.Figure: A Plotly figure object containing the visualization.\n",
    "    \"\"\"\n",
    "    # Modify the visualize_topics_per_class method from bertopic to be able to print a barchart vertically\n",
    "    def visualize_topics_per_class_orient(topic_model,\n",
    "                                topics_per_class: pd.DataFrame,\n",
    "                                top_n_topics: Union[int,None] = None,\n",
    "                                topics: List[int] = None,\n",
    "                                normalize_frequency: bool = False,\n",
    "                                percentage_by: Union[str,None] = None,\n",
    "                                custom_labels: Union[bool, str] = False,\n",
    "                                title: str = \"<b>Topics per Class</b>\",\n",
    "                                width: int = 1250,\n",
    "                                height: int = 900,\n",
    "                                orient: str = \"h\") -> go.Figure:\n",
    "        \"\"\"\n",
    "        Visualizes the distribution of topics per class.\n",
    "\n",
    "        Parameters:\n",
    "        topic_model : The trained BERTopic model.\n",
    "        topics_per_class (pd.DataFrame): A DataFrame containing the topics per class.\n",
    "        top_n_topics (int, optional): The number of top topics to visualize. Defaults to 10.\n",
    "        topics (List[int], optional): A list of specific topics to visualize. Defaults to None.\n",
    "        normalize_frequency (bool, optional): Whether to normalize the frequency. Defaults to False.\n",
    "        percentage_by (string, optional): Which percentage calcul to use for the representation of the data. Defaults to None.\n",
    "        custom_labels (Union[bool, str], optional): Whether to use custom labels for the topics. Defaults to False.\n",
    "        title (str, optional): The title of the plot. Defaults to \"<b>Topics per Class</b>\".\n",
    "        width (int, optional): The width of the plot. Defaults to 1250.\n",
    "        height (int, optional): The height of the plot. Defaults to 900.\n",
    "        orient (str, optional): The orientation of the plot. Defaults to \"h\".\n",
    "\n",
    "        Returns:\n",
    "        go.Figure: A Plotly figure object containing the visualization.\n",
    "        \"\"\"\n",
    "        colors = [\"#E69F00\", \"#56B4E9\", \"#009E73\", \"#F0E442\", \"#D55E00\", \"#0072B2\", \"#CC79A7\"]\n",
    "\n",
    "        if percentage_by not in [\"Topic\",\"Class\",None] :\n",
    "            raise ValueError(\"'percentage_by' possible values are ['Topic','Class', None]\")\n",
    "    \n",
    "        # Select topics based on top_n and topics args\n",
    "        freq_df = topic_model.get_topic_freq()\n",
    "        freq_df = freq_df.loc[freq_df.Topic != -1, :]\n",
    "        if topics is not None:\n",
    "            selected_topics = list(topics)\n",
    "        elif top_n_topics is not None:\n",
    "            selected_topics = sorted(freq_df.Topic.to_list()[:top_n_topics])\n",
    "        else:\n",
    "            selected_topics = sorted(freq_df.Topic.to_list())\n",
    "\n",
    "        # Prepare data\n",
    "        if isinstance(custom_labels, str):\n",
    "            topic_names = [[[str(topic), None]] + topic_model.topic_aspects_[custom_labels][topic] for topic in topics]\n",
    "            topic_names = [\"_\".join([label[0] for label in labels[:4]]) for labels in topic_names]\n",
    "            topic_names = [label if len(label) < 30 else label[:27] + \"...\" for label in topic_names]\n",
    "            topic_names = {key: topic_names[index] for index, key in enumerate(topic_model.topic_labels_.keys())}\n",
    "        elif topic_model.custom_labels_ is not None and custom_labels:\n",
    "            topic_names = {key: topic_model.custom_labels_[key + topic_model._outliers] for key, _ in topic_model.topic_labels_.items()}\n",
    "        else:\n",
    "            topic_names = {key: value[:40] + \"...\" if len(value) > 40 else value\n",
    "                        for key, value in topic_model.topic_labels_.items()}\n",
    "        topics_per_class[\"Name\"] = topics_per_class.Topic.map(topic_names)\n",
    "        data = topics_per_class.loc[topics_per_class.Topic.isin(selected_topics), :]\n",
    "\n",
    "        # Add traces\n",
    "        fig = go.Figure()\n",
    "        for index, topic in enumerate(selected_topics):\n",
    "            if index == 0:\n",
    "                visible = True\n",
    "            else:\n",
    "                visible = \"legendonly\"\n",
    "            trace_data = data.loc[data.Topic == topic, :]\n",
    "            topic_name = trace_data.Name.values[0]\n",
    "            words = trace_data.Words.values\n",
    "\n",
    "        # Check if 'percentage_by' is defined and if the corresponding percentage column exists, and use it for x values if it does\n",
    "            if percentage_by is not None :\n",
    "                col_name = f'{percentage_by}_Percentage'\n",
    "                if col_name in trace_data.columns:\n",
    "                    x = trace_data[col_name]\n",
    "                else:\n",
    "                    raise ValueError(f\"{col_name} column does not exist\")\n",
    "            elif normalize_frequency:\n",
    "                x = normalize(trace_data.Frequency.values.reshape(1, -1))[0]\n",
    "            else:\n",
    "                x = trace_data.Frequency\n",
    "\n",
    "            ### Old part from the source github of bertopic ###\n",
    "            # fig.add_trace(go.Bar(y=trace_data.Class,\n",
    "            #                      x=x,\n",
    "            #                      visible=visible,\n",
    "            #                      marker_color=colors[index % 7],\n",
    "            #                      hoverinfo=\"text\",\n",
    "            #                      name=topic_name,\n",
    "            #                      orientation=\"h\",\n",
    "            #                      hovertext=[f'<b>Topic {topic}</b><br>Words: {word}' for word in words]))\n",
    "            \n",
    "            fig.add_trace(go.Bar(y=trace_data.Class if orient == \"h\" else x,\n",
    "                                x=x if orient == \"h\" else trace_data.Class,\n",
    "                                visible=visible,\n",
    "                                marker_color=colors[index % 7],\n",
    "                                hoverinfo=\"text\",\n",
    "                                name=topic_name,\n",
    "                                orientation=orient,\n",
    "                                hovertext=[f'<b>Topic {topic_names[topic]}</b><br>Words: {word}' for word in words] if percentage_by==None else [f'<b>Topic {topic_names[topic]}</b><br>Words: {word}<br>Percentage: {p}%' for word, p in zip(words, x)]\n",
    "                                ))\n",
    "\n",
    "        # Styling of the visualization\n",
    "        fig.update_xaxes(showgrid=True)\n",
    "        fig.update_yaxes(showgrid=True)\n",
    "        fig.update_layout(\n",
    "            xaxis_title=\"Normalized Frequency\" if normalize_frequency else \"Frequency\",\n",
    "            yaxis_title=\"Class\",\n",
    "            barmode='stack' if stacked else \"group\",\n",
    "            title={\n",
    "                'text': f\"{title}\",\n",
    "                'y': .95,\n",
    "                'x': 0.40,\n",
    "                'xanchor': 'center',\n",
    "                'yanchor': 'top',\n",
    "                'font': dict(\n",
    "                    size=22,\n",
    "                    color=\"Black\")\n",
    "            },\n",
    "            template=\"simple_white\",\n",
    "            width=width,\n",
    "            height=height,\n",
    "            hoverlabel=dict(\n",
    "                bgcolor=\"white\",\n",
    "                font_size=16,\n",
    "                font_family=\"Rockwell\"\n",
    "            ),\n",
    "            legend=dict(\n",
    "                title=\"<b>Global Topic Representation\",\n",
    "            )\n",
    "        )\n",
    "        return fig\n",
    "\n",
    "    if viz_from_source==True and (orient!=\"h\" or percentage_by!=None):\n",
    "        raise ValueError(\"the option 'orient' and 'percentage_by' are not available in the visualization from bertopic source code\")\n",
    "    if orient==\"h\" and percentage_by==None and viz_from_source==True:\n",
    "        # using the source method to do it, without having the possibility to choose the orient (at the date of 09/2023)\n",
    "        # we keep the use of the source method even if we could use only the new visualize_topics_per_class_orient. Because it permits to know and enjoy the modifications done in visualize_topics_per_class in the future by the owner of this source code\n",
    "        fig = topic_model.visualize_topics_per_class(topics_per_class, top_n_topics=None, **kwargs)\n",
    "    else:  \n",
    "        # using the modified source method to do it, adding the option to print the chart vertically\n",
    "        fig = visualize_topics_per_class_orient(topic_model, topics_per_class, orient=orient, percentage_by=percentage_by, **kwargs)\n",
    "\n",
    "    return fig\n",
    "\n",
    "def old_create_chart_per_class(\n",
    "                            df, \n",
    "                            bertopic_model, \n",
    "                            classes_column, \n",
    "                            filter=False, \n",
    "                            filter_group=None, \n",
    "                            filter_value=None, \n",
    "                            sortedBy=None, \n",
    "                            ascending=True, \n",
    "                            orient=\"h\",\n",
    "                            viz_from_source=False,\n",
    "                            **kwargs):\n",
    "    \"\"\"\n",
    "    Create a chart representing the topics per class.\n",
    "\n",
    "    This function takes as input a dataframe `df`, a BERTopic model `bertopic_model`, a column name `classes_column` representing the classes, an optional boolean parameter `filter` which determines whether to filter the data based on a subclass, an optional parameter `subclass_name` representing the column name of the subclass to filter on, an optional parameter `subclass_value` representing the value of the subclass to filter on, an optional parameter `sortedBy` which can be used to sort the topics by either \"Frequency\" or \"Name\", an optional boolean parameter `ascending` which determines the sorting order (ascending or descending), an orientation `orient` which can be either horizontal (\"h\") or vertical (\"v\"), and additional keyword arguments `**kwargs`.\n",
    "\n",
    "    The function first calls the `create_topics_per_class_df` function to create a dataframe representing the topics per class. Then, it calls the `visualize_topics_per_class_options` function to create a chart from this dataframe. The resulting chart is then returned.\n",
    "\n",
    "    Parameters:\n",
    "        df (pandas.DataFrame): The input dataframe containing the data to be visualized.\n",
    "        bertopic_model (BERTopic): The BERTopic model used to calculate the topics per class.\n",
    "        classes_column (str): The name of the column in `df` representing the classes.\n",
    "        filter (bool): An optional boolean parameter used to determine whether to filter the data based on a subclass. Defaults to False.\n",
    "        filter_group (str): An optional parameter representing the column name of the subclass to filter on. Only used if `filter` is True. Defaults to None.\n",
    "        filter_value: An optional parameter representing the value of the subclass to filter on. Only used if `filter` is True. Defaults to None.\n",
    "        sortedBy (str): An optional parameter used to sort the topics by either \"Frequency\" or \"Name\". Defaults to None.\n",
    "        ascending (bool): An optional boolean parameter used to determine the sorting order. If True, sorts in ascending order. If False, sorts in descending order. Defaults to True.\n",
    "        orient (str): The orientation of the visualization. Can be either \"h\" for horizontal or \"v\" for vertical. Defaults to \"h\".\n",
    "        **kwargs: Additional keyword arguments passed to the visualization method.\n",
    "\n",
    "    Returns:\n",
    "        plotly.graph_objs.Figure: The resulting chart representing the topics per class.\n",
    "    \"\"\"\n",
    "    topics_per_class = create_topics_per_class_df(df, bertopic_model, classes_column, filter=filter, filter_group=filter_group, filter_value=filter_value, sortedBy=sortedBy, ascending=ascending)\n",
    "    fig = visualize_topics_per_class_options(bertopic_model, topics_per_class, orient=orient, viz_from_source=viz_from_source, **kwargs)\n",
    "\n",
    "    return fig \n",
    "\n",
    "def create_chart_per_class(\n",
    "                            df, \n",
    "                            bertopic_model, \n",
    "                            classes_column, \n",
    "                            filter_value=None, \n",
    "                            sortedBy=None, \n",
    "                            ascending=True, \n",
    "                            orient=\"h\",\n",
    "                            viz_from_source=False,\n",
    "                            stacked=False,\n",
    "                            percentage_by=None,\n",
    "                            **kwargs):\n",
    "    \"\"\"\n",
    "    Create a chart representing the topics per class.\n",
    "\n",
    "    This function takes as input a dataframe `df`, a BERTopic model `bertopic_model`, a column name `classes_column` representing the classes, an optional parameter `filter_value` representing the value of the class to filter on, an optional parameter `sortedBy` which can be used to sort the topics by either \"Frequency\" or \"Name\", an optional boolean parameter `ascending` which determines the sorting order (ascending or descending), an orientation `orient` which can be either horizontal (\"h\") or vertical (\"v\"), and additional keyword arguments `**kwargs`.\n",
    "\n",
    "    The function first calls the `create_topics_per_class_df` function to create a dataframe representing the topics per class. Then, it calls the `visualize_topics_per_class_options` function to create a chart from this dataframe. The resulting chart is then returned.\n",
    "\n",
    "    Parameters:\n",
    "        df (pandas.DataFrame): The input dataframe containing the data to be visualized.\n",
    "        bertopic_model (BERTopic): The BERTopic model used to calculate the topics per class.\n",
    "        classes_column (str): The name of the column in `df` representing the classes.\n",
    "        filter_value: An optional parameter representing the value of the subclass to filter on. Only used if `filter` is True. Defaults to None.\n",
    "        sortedBy (str): An optional parameter used to sort the topics by either \"Frequency\" or \"Name\". Defaults to None.\n",
    "        ascending (bool): An optional boolean parameter used to determine the sorting order. If True, sorts in ascending order. If False, sorts in descending order. Defaults to True.\n",
    "        orient (str): The orientation of the visualization. Can be either \"h\" for horizontal or \"v\" for vertical. Defaults to \"h\".\n",
    "        **kwargs: Additional keyword arguments passed to the visualization method.\n",
    "\n",
    "    Returns:\n",
    "        plotly.graph_objs.Figure: The resulting chart representing the topics per class.\n",
    "    \"\"\"\n",
    "    topics_per_class = create_topics_per_class_df(df, bertopic_model, classes_column, filter_value=filter_value, sortedBy=sortedBy, ascending=ascending)\n",
    "    fig = visualize_topics_per_class_options(bertopic_model, topics_per_class, orient=orient, viz_from_source=viz_from_source, stacked=stacked, percentage_by=percentage_by, **kwargs)\n",
    "\n",
    "    return fig \n",
    "\n",
    "def save_graph_html(fig, path, name):\n",
    "    \"\"\"\n",
    "    Saves a Plotly figure as an HTML file at the specified path.\n",
    "\n",
    "    Parameters:\n",
    "    fig (go.Figure): The Plotly figure to save.\n",
    "    path (str): The directory where the HTML file will be saved.\n",
    "    name (str): The name of the HTML file (without the .html extension).\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Create the directory if it doesn't exist\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "        \n",
    "    return fig.write_html(path+\"/\"+name+\".html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "# Define the colors\n",
    "colors = [\"#FFFB8D\", \"#F5F05F\", \"#FFC974\", \"#FFA674\", \"#5ECEAF\", \"#8CE4CC\", \"#5DFBEA\"]\n",
    "\n",
    "brand_colors = {\n",
    "    \"violet\": {\n",
    "        \"light\": \"#C8AADE\",\n",
    "        \"normal\": \"#9D6FC0\",\n",
    "        \"dark\": \"#7C46A5\",\n",
    "        \"dark2\": \"#672B95\"\n",
    "    },\n",
    "    \"bleu marine\": {\n",
    "        \"light\": \"#C5DBF5\",\n",
    "        \"normal\": \"#93B8E4\",\n",
    "        \"dark\": \"#6795CD\",\n",
    "        \"dark2\": \"#4174B2\"\n",
    "    },\n",
    "    \"bleu roi\": {\n",
    "        \"light\": \"#9DC1F6\",\n",
    "        \"normal\": \"#5C9EFF\",\n",
    "        \"dark\": \"#3B8AFF\",\n",
    "        \"dark2\": \"#096CFF\"\n",
    "    },\n",
    "    \"cyan\": {\n",
    "        \"light\": \"#C4FEF8\",\n",
    "        \"normal\": \"#8CFCF0\",\n",
    "        \"dark\": \"#5EF8E8\",\n",
    "        \"dark2\": \"#32EFDB\"\n",
    "    },\n",
    "    \"bleu-vert\": {\n",
    "        \"light\": \"#C1F5E7\",\n",
    "        \"normal\": \"#8CE4CC\",\n",
    "        \"dark\": \"#5ECEAF\",\n",
    "        \"dark2\": \"#37B290\"\n",
    "    },\n",
    "    \"vert\": {\n",
    "        \"light\": \"#D7FBC6\",\n",
    "        \"normal\": \"#B4F496\",\n",
    "        \"dark\": \"#96EC6C\",\n",
    "        \"dark2\": \"#78E146\"\n",
    "    },\n",
    "    \"jaune\": {\n",
    "        \"light\": \"#FFFEB2\",\n",
    "        \"normal\": \"#FFFD87\",\n",
    "        \"dark\": \"#FFFC4C\",\n",
    "        \"dark2\": \"#F9F400\"\n",
    "    },\n",
    "    \"orange\": {\n",
    "        \"light\": \"#FFE8BD\",\n",
    "        \"normal\": \"#FFD78E\",\n",
    "        \"dark\": \"#FFC761\",\n",
    "        \"dark2\": \"#FFB836\"\n",
    "    },\n",
    "    \"orange-rouge\": {\n",
    "        \"light\": \"#FFDCC9\",\n",
    "        \"normal\": \"#FFC09D\",\n",
    "        \"dark\": \"#FFA674\",\n",
    "        \"dark2\": \"#FF8E4F\"\n",
    "    },\n",
    "    \"rouge\": {\n",
    "        \"light\": \"#FFD6D6\",\n",
    "        \"normal\": \"#FF8F8F\",\n",
    "        \"dark\": \"#FF6B6B\",\n",
    "        \"dark2\": \"#FF4C4C\"\n",
    "    },\n",
    "}\n",
    "\n",
    "def hex_to_rgb(color):\n",
    "    return mcolors.hex2color(color)\n",
    "\n",
    "def display_palette(palette):\n",
    "    fig, ax = plt.subplots(len(palette), 1, figsize=(2, 12),\n",
    "                           dpi=80, sharex=True, sharey=True)\n",
    "    for i, color in enumerate(palette):\n",
    "        ax[i].imshow([[hex_to_rgb(palette[color][shade]) for shade in palette[color]]])\n",
    "        ax[i].axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Create the colormap\n",
    "colormap = LinearSegmentedColormap.from_list(\"my_colormap\", colors, N=12)\n",
    "\n",
    "# Generate a gradient image for demonstration\n",
    "gradient = np.linspace(0, 1, 256)  # Gradient from 0 to 1\n",
    "gradient = np.vstack((gradient, gradient))  # Stack to make a 2D image\n",
    "\n",
    "# plt.imshow(gradient, aspect='auto', cmap=colormap)\n",
    "# plt.show()\n",
    "\n",
    "# Usage\n",
    "# display_palette(brand_colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res_df = create_topics_per_class_df(df4, topic_model_merged, \"year\", sortedBy=\"Class\", filter=True, filter_group=\"year\",filter_value=\"2018\")\n",
    "# visualize_topics_per_class_options(topic_model_merged, res_df, viz_from_source=False, custom_labels=True, percentage_by=\"Class\", stacked=True)\n",
    "# res_df\n",
    "# create_chart_per_class(df4, topic_model_merged, \"year\", percentage_by=\"Class\", stacked=True, custom_labels=True)\n",
    "\n",
    "res_df = create_topics_per_class_df(df4, topic_model_merged, \"year\", filter_value=\"2018\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hole": 0.6,
         "hovertemplate": "%{label}: %{value}<extra></extra>",
         "labels": [
          "Automation Components",
          "Technical Support",
          "Delivery Deadlines",
          "Problem Solving & Comm",
          "Power Supply Issues",
          "Customer Support",
          "Product Evaluation",
          "Pricing",
          "Assistance",
          "Touch Screens",
          "Frequency Converters",
          "Positive feedback",
          "Quick Customer Service"
         ],
         "type": "pie",
         "values": [
          2124,
          379,
          487,
          51,
          103,
          332,
          296,
          67,
          24,
          84,
          91,
          7,
          2
         ]
        }
       ],
       "layout": {
        "autosize": false,
        "height": 500,
        "legend": {
         "title": {
          "text": "Topics"
         }
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "font": {
          "color": "rgb(107, 107, 107)",
          "size": 20
         },
         "text": "Topics' Repartition",
         "x": 0.5,
         "xanchor": "center",
         "y": 0.9,
         "yanchor": "top"
        },
        "width": 800
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_donut_chart(df, value):\n",
    "    if value not in [\"Frequency\",\"Topic_Percentage\",\"Class_Percentage\"]:\n",
    "        raise ValueError(f\"{value} is not a discrete column from the df in parameter\")\n",
    "    palette = [brand_colors[color][\"dark2\"] for color in brand_colors]\n",
    "    # Create the donut chart\n",
    "    fig = go.Figure(data=[go.Pie(labels=df['Name'], \n",
    "                                 values=df[value], \n",
    "                                 hole=.6,\n",
    "                                #  marker=dict(colors=palette), \n",
    "                                # default:['#1f77b4',  '#ff7f0e',  '#2ca02c',  '#d62728',  '#9467bd',  '#8c564b',  '#e377c2',  '#7f7f7f',  '#bcbd22',  '#17becf']\n",
    "                                #  color_discrete_sequence=palette,\n",
    "                                 hovertemplate='%{label}: %{value}<extra></extra>'\n",
    "                                )\n",
    "                    ])\n",
    "    \n",
    "    fig.update_layout(\n",
    "        legend_title_text='Topics',\n",
    "        title={'text': \"Topics' Repartition\",\n",
    "               'y':0.9,'x':0.5,\n",
    "               'xanchor': 'center','yanchor': 'top'},\n",
    "        title_font=dict(size=20,\n",
    "                        color='rgb(107, 107, 107)'),\n",
    "        autosize=False,\n",
    "        width=800,\n",
    "        height=500\n",
    "    )\n",
    "    return fig\n",
    "\n",
    "# Call the function with your dataframe and a specific year\n",
    "fig = create_donut_chart(res_df, \"Frequency\")\n",
    "fig\n",
    "# Save the figure as an HTML file\n",
    "# pio.write_html(fig, 'my_figure.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "branchvalues": "total",
         "hovertext": [
          "12.09%",
          "6.28%",
          "12.17%",
          "6.32%",
          "13.25%",
          "3.74%",
          "6.61%",
          "5.35%",
          "3.95%",
          "5.66%",
          "5.25%",
          "6.26%",
          "3.52%",
          "4.42%",
          "2.51%",
          "2.57%",
          "0.05%",
          "26.17%",
          "61.02%",
          "81.14%",
          "77.55%",
          "27.67%",
          "100.00%",
          "100.00%",
          "22.45%",
          "18.86%",
          "28.84%",
          "71.36%",
          "26.48%",
          "80.22%",
          "99.79%",
          "18.06%",
          "18.51%",
          "72.76%",
          "76.55%",
          "3.52%",
          "44.32%",
          "98.11%",
          "10.80%",
          "11.29%",
          "55.68%",
          "27.24%",
          "8.98%",
          "1.87%",
          "15.56%",
          "100.00%",
          "1.89%",
          "7.92%",
          "3.47%",
          "0.21%",
          "1.49%",
          "0.02%",
          "0.21%",
          "69.07%",
          "32.11%",
          "9.86%",
          "93.06%",
          "93.16%",
          "43.85%",
          "20.06%",
          "40.16%",
          "99.51%",
          "28.08%",
          "26.38%",
          "15.99%",
          "56.62%",
          "10.87%",
          "0.99%",
          "80.95%",
          "5.85%",
          "7.76%",
          "100.00%",
          "8.68%",
          "100.00%",
          "5.02%",
          "3.57%",
          "2.78%",
          "2.74%",
          "95.92%",
          "66.67%",
          "18.26%",
          "19.05%",
          "1.54%",
          "71.43%",
          "2.04%",
          "33.33%",
          "2.62%",
          "2.04%",
          "0.91%",
          "0.05%",
          "0.49%",
          "100.00%",
          "14.29%",
          "9.52%",
          "4.76%",
          "32.74%"
         ],
         "labels": [
          "Italy",
          "Nordic & Baltics",
          "DACH",
          "Iberia",
          "East Asia Japan",
          "Greater India",
          "US",
          "France",
          "Middle East and Africa",
          "CEEI",
          "China & HK",
          "South America",
          "Pacific",
          "BeNe",
          "UK and Ireland",
          "Canada",
          "Mexico & Central America",
          "Sweden",
          "Germany",
          "Spain",
          "North East Asia",
          "Switzerland",
          "India",
          "USA",
          "South East Asia",
          "Portugal",
          "Finland & Baltics",
          "Turkey Central Asia and Pakistan",
          "Denmark",
          "Middle Eastern Europe",
          "China",
          "Argentina, Uruguay and Paraguay",
          "Norway",
          "Australia",
          "Brazil",
          "Chile",
          "Belgium",
          "United Kingdom",
          "Southeast Europe",
          "Austria",
          "Netherlands",
          "New Zealand",
          "Israel",
          "Andean Cluster",
          "Anglophone Africa",
          "Mexico",
          "Ireland",
          "Saudi Arabia & Yemen",
          "North East Africa and Levant",
          "Francophone Africa",
          "Gulf",
          "Liechtenstein",
          "Hong Kong & Macao",
          "Japan",
          "Thailand",
          "Vietnam",
          "Finland",
          "Turkey",
          "Poland",
          "Korea, Republic of",
          "Czech Republic",
          "Argentina",
          "Indonesia",
          "Singapore",
          "Slovakia",
          "Romania",
          "Taiwan",
          "Pakistan",
          "Colombia",
          "Kazakhstan",
          "Bulgaria",
          "South Africa",
          "Croatia",
          "Saudi Arabia",
          "Greece",
          "Malaysia",
          "Lithuania",
          "Serbia",
          "Egypt",
          "Morocco",
          "Hungary",
          "Peru",
          "Estonia",
          "United Arab Emirates",
          "Lebanon",
          "Dominican Republic",
          "Latvia",
          "Jordan",
          "Slovenia",
          "San Marino",
          "Paraguay",
          "Hong Kong",
          "Kuwait",
          "Qatar",
          "Oman",
          "Geo Levels"
         ],
         "parents": [
          "Geo Levels",
          "Geo Levels",
          "Geo Levels",
          "Geo Levels",
          "Geo Levels",
          "Geo Levels",
          "Geo Levels",
          "Geo Levels",
          "Geo Levels",
          "Geo Levels",
          "Geo Levels",
          "Geo Levels",
          "Geo Levels",
          "Geo Levels",
          "Geo Levels",
          "Geo Levels",
          "Geo Levels",
          "Nordic & Baltics",
          "DACH",
          "Iberia",
          "East Asia Japan",
          "DACH",
          "Greater India",
          "US",
          "East Asia Japan",
          "Iberia",
          "Nordic & Baltics",
          "Middle East and Africa",
          "Nordic & Baltics",
          "CEEI",
          "China & HK",
          "South America",
          "Nordic & Baltics",
          "Pacific",
          "South America",
          "South America",
          "BeNe",
          "UK and Ireland",
          "CEEI",
          "DACH",
          "BeNe",
          "Pacific",
          "CEEI",
          "South America",
          "Middle East and Africa",
          "Mexico & Central America",
          "UK and Ireland",
          "Middle East and Africa",
          "Middle East and Africa",
          "Middle East and Africa",
          "Middle East and Africa",
          "DACH",
          "China & HK",
          "North East Asia",
          "South East Asia",
          "South East Asia",
          "Finland & Baltics",
          "Turkey Central Asia and Pakistan",
          "Middle Eastern Europe",
          "North East Asia",
          "Middle Eastern Europe",
          "Argentina, Uruguay and Paraguay",
          "South East Asia",
          "South East Asia",
          "Middle Eastern Europe",
          "Southeast Europe",
          "North East Asia",
          "Turkey Central Asia and Pakistan",
          "Andean Cluster",
          "Turkey Central Asia and Pakistan",
          "Southeast Europe",
          "Anglophone Africa",
          "Southeast Europe",
          "Saudi Arabia & Yemen",
          "Southeast Europe",
          "South East Asia",
          "Finland & Baltics",
          "Southeast Europe",
          "North East Africa and Levant",
          "Francophone Africa",
          "Southeast Europe",
          "Andean Cluster",
          "Finland & Baltics",
          "Gulf",
          "North East Africa and Levant",
          "Francophone Africa",
          "Finland & Baltics",
          "North East Africa and Levant",
          "Southeast Europe",
          "Italy",
          "Argentina, Uruguay and Paraguay",
          "Hong Kong & Macao",
          "Gulf",
          "Gulf",
          "Gulf",
          ""
         ],
         "type": "sunburst",
         "values": [
          4328,
          2247,
          4359,
          2264,
          4744,
          1339,
          2367,
          1914,
          1414,
          2027,
          1878,
          2243,
          1259,
          1584,
          898,
          919,
          18,
          588,
          2660,
          1837,
          3679,
          1206,
          1339,
          2367,
          1065,
          427,
          648,
          1009,
          595,
          1626,
          1874,
          405,
          416,
          916,
          1717,
          79,
          702,
          881,
          219,
          492,
          882,
          343,
          182,
          42,
          220,
          18,
          17,
          112,
          49,
          3,
          21,
          1,
          4,
          2541,
          342,
          105,
          603,
          940,
          713,
          738,
          653,
          403,
          299,
          281,
          260,
          124,
          400,
          10,
          34,
          59,
          17,
          220,
          19,
          112,
          11,
          38,
          18,
          6,
          47,
          2,
          40,
          8,
          10,
          15,
          1,
          1,
          17,
          1,
          2,
          2,
          2,
          4,
          3,
          2,
          1,
          35804
         ]
        }
       ],
       "layout": {
        "height": 1000,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "font": {
          "color": "rgb(107, 107, 107)",
          "size": 20
         },
         "text": "Geographical Distribution",
         "x": 0.5,
         "xanchor": "center",
         "y": 0.9,
         "yanchor": "top"
        },
        "width": 1100
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def build_hierarchical_dataframe(df, levels, value_column, color_columns=None):\n",
    "    df_sunburst = df[levels + [value_column]].drop_duplicates()\n",
    "\n",
    "    if color_columns:\n",
    "        df_sunburst[color_columns] = df.groupby(levels)[color_columns].mean()\n",
    "    \n",
    "    return df_sunburst\n",
    "\n",
    "def old_build_sunburst_lists(df, levels):\n",
    "    labels_set = set()\n",
    "    labels = []\n",
    "    parents = []\n",
    "    values = []\n",
    "    percentages = []\n",
    "\n",
    "    for i in range(len(levels)):\n",
    "        # Get lists for current level and parent level\n",
    "        current_level = df[levels[i]].tolist()\n",
    "        parent_level = [''] * len(current_level) if i == 0 else df[levels[i - 1]].tolist()\n",
    "\n",
    "        # Get parents for current level\n",
    "        parents_current_level = ['' if current_level[j] == parent_level[j] else parent_level[j] for j in range(len(current_level))]\n",
    "\n",
    "        # Append current level and parents to labels and parents lists, avoiding duplicates\n",
    "        for j in range(len(current_level)):\n",
    "            if current_level[j] not in labels_set:\n",
    "                labels.append(current_level[j])\n",
    "                parents.append(parents_current_level[j])\n",
    "                labels_set.add(current_level[j])\n",
    "\n",
    "    # Add 'Geo' as the parent of all 'Zone' labels\n",
    "    for i in range(len(labels)):\n",
    "        if parents[i] == '':\n",
    "            parents[i] = 'Geo Levels'\n",
    "\n",
    "    # Add 'Geo' to the labels list with no parent\n",
    "    labels.append('Geo Levels')\n",
    "    parents.append('')\n",
    "\n",
    "    # Compute values for each label\n",
    "    for label in labels:\n",
    "        if label in df['Account Country'].values:\n",
    "            # If label is an 'Account Country', use the corresponding 'Count' value\n",
    "            values.append(df.loc[df['Account Country'] == label, 'Count'].values[0])\n",
    "        elif label in df['Clusters'].values:\n",
    "            # If label is a 'Clusters', sum the 'Count' values of its 'Account Country'\n",
    "            values.append(df.loc[df['Clusters'] == label, 'Count'].sum())\n",
    "        elif label in df['Zone'].values:\n",
    "            # If label is a 'Zone', sum the 'Count' values of its 'Clusters'\n",
    "            clusters_in_zone = df.loc[df['Zone'] == label, 'Clusters'].unique()\n",
    "            values.append(df.loc[df['Clusters'].isin(clusters_in_zone), 'Count'].sum())\n",
    "        elif label == 'Geo Levels':\n",
    "            values.append(df[\"Count\"].sum())\n",
    "\n",
    "    # Create a dictionary to map labels to their corresponding values\n",
    "    value_dict = dict(zip(labels, values))\n",
    "\n",
    "    # Calculate percentages based on the parent's value\n",
    "    for i in range(len(labels)):\n",
    "        parent_value = value_dict[parents[i]] if parents[i] else sum(values)\n",
    "        percentages.append(values[i] / parent_value * 100)\n",
    "            \n",
    "    return labels, parents, values, percentages\n",
    "\n",
    "def get_current_level_and_parents(df, levels):\n",
    "    labels_set = set()\n",
    "    labels = []\n",
    "    parents = []\n",
    "\n",
    "    for i in range(len(levels)):\n",
    "        current_level = df[levels[i]].tolist()\n",
    "        parent_level = [''] * len(current_level) if i == 0 else df[levels[i - 1]].tolist()\n",
    "\n",
    "        parents_current_level = ['' if current_level[j] == parent_level[j] else parent_level[j] for j in range(len(current_level))]\n",
    "\n",
    "        for j in range(len(current_level)):\n",
    "            if current_level[j] not in labels_set:\n",
    "                labels.append(current_level[j])\n",
    "                parents.append(parents_current_level[j])\n",
    "                labels_set.add(current_level[j])\n",
    "\n",
    "    return labels, parents\n",
    "\n",
    "def add_unique_parent(labels, parents, unique_parent_name):\n",
    "    for i in range(len(labels)):\n",
    "        if parents[i] == '':\n",
    "            parents[i] = unique_parent_name\n",
    "\n",
    "    labels.append(unique_parent_name)\n",
    "    parents.append('')\n",
    "\n",
    "    return labels, parents\n",
    "\n",
    "def compute_values(df, labels):\n",
    "    values = []\n",
    "\n",
    "    for label in labels:\n",
    "        if label in df['Account Country'].values:\n",
    "            values.append(df.loc[df['Account Country'] == label, 'Count'].values[0])\n",
    "        elif label in df['Clusters'].values:\n",
    "            values.append(df.loc[df['Clusters'] == label, 'Count'].sum())\n",
    "        elif label in df['Zone'].values:\n",
    "            clusters_in_zone = df.loc[df['Zone'] == label, 'Clusters'].unique()\n",
    "            values.append(df.loc[df['Clusters'].isin(clusters_in_zone), 'Count'].sum())\n",
    "        elif label == 'Geo Levels':\n",
    "            values.append(df[\"Count\"].sum())\n",
    "\n",
    "    return values\n",
    "\n",
    "def old_calculate_percentages(labels, parents, values):\n",
    "    value_dict = dict(zip(labels, values))\n",
    "    percentages = []\n",
    "\n",
    "    for i in range(len(labels)):\n",
    "        parent_value = value_dict[parents[i]] if parents[i] else sum(values)\n",
    "        percentages.append(values[i] / parent_value * 100)\n",
    "\n",
    "    return percentages\n",
    "\n",
    "def calculate_percentages(df, labels, parents, values, percentage_by_zone=False):\n",
    "    value_dict = dict(zip(labels, values))\n",
    "    percentages = []\n",
    "\n",
    "    for i in range(len(labels)):\n",
    "        if percentage_by_zone and parents[i] in df['Zone'].values:\n",
    "            parent_value = df.loc[df['Zone'] == parents[i], 'Count'].sum()\n",
    "        else:\n",
    "            parent_value = value_dict[parents[i]] if parents[i] else sum(values)\n",
    "        \n",
    "        percentages.append(values[i] / parent_value * 100)\n",
    "\n",
    "    return percentages\n",
    "\n",
    "def build_sunburst_lists(df, levels, unique_parent=True, percentage_by_zone=False, unique_parent_name=\"Geo Levels\"):\n",
    "    labels, parents = get_current_level_and_parents(df, levels)\n",
    "    if unique_parent:\n",
    "        labels, parents = add_unique_parent(labels, parents, unique_parent_name)\n",
    "    values = compute_values(df, labels)\n",
    "    percentages = calculate_percentages(df, labels, parents, values, percentage_by_zone)\n",
    "\n",
    "    return labels, parents, values, percentages\n",
    "\n",
    "def create_sunburst(labels, parents, values, percentages, **sunburst_kwargs):\n",
    "    # Create a list of hover texts that includes the percentage for each label\n",
    "    hover_text = [f'{percentage:.2f}%' for _, _, percentage in zip(labels, values, percentages)]\n",
    "    fig = go.Figure(data=go.Sunburst(\n",
    "        labels=labels,\n",
    "        parents=parents,\n",
    "        values=values,\n",
    "        branchvalues='total',\n",
    "        hovertext=hover_text,\n",
    "        **sunburst_kwargs\n",
    "    ))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title={'text': f\"Geographical Distribution\",\n",
    "               'y':0.9,'x':0.5,\n",
    "               'xanchor': 'center','yanchor': 'top'},\n",
    "        title_font=dict(size=20,\n",
    "                        color='rgb(107, 107, 107)'),\n",
    "        width=1100,\n",
    "        height=1000\n",
    "    )\n",
    "\n",
    "    return fig\n",
    "\n",
    "df5=df4.copy()\n",
    "# df5 = filter_docs(df4, \"sentiment_label\", \"positive\")[0]\n",
    "\n",
    "df5['Count'] = df5.groupby('Account Country')['Account Country'].transform('count')\n",
    "res_df5 = build_hierarchical_dataframe(df5, ['Zone','Clusters','Account Country'], 'Count')\n",
    "\n",
    "labels, parents, values, percentages = build_sunburst_lists(res_df5, ['Zone','Clusters','Account Country'], percentage_by_zone=False, unique_parent=True)\n",
    "\n",
    "create_sunburst(labels, parents, values, percentages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Graph barchart topics by sentiment\n",
    "\n",
    "# Code without using the create_chart_per_class wrapper function\n",
    "# create topics_per_class df in order to run the visualization then.\n",
    "# topics_per_class = create_topics_per_class_df(df4, topic_model_merged, \"sentiment_label\", sortedBy=\"Frequency\")\n",
    "# visualize the topic representation of major topics per Sentiment (positive, negative, neutral):\n",
    "# fig = visualize_topics_per_class_options(topic_model_merged, topics_per_class, orient=\"v\", custom_labels=True, title=\"Topics per Sentiment\", width=500, height=750)\n",
    "\n",
    "# Code using the create_chart_per_class wrapper function\n",
    "fig = create_chart_per_class(df4, topic_model_merged, \"sentiment_label\", \n",
    "                             sortedBy=\"Frequency\", \n",
    "                             orient=\"v\", \n",
    "                             custom_labels=True, \n",
    "                             percentage_by=\"Class\",\n",
    "                             title=\"Topics per Sentiment\", \n",
    "                             width=500, height=750)\n",
    "\n",
    "# Save the figure as an HTML file\n",
    "# save_graph_html(fig, \"../data/graphs/Sentiment_Analysis/by_sentiment/repartition_per_topic/global\", \"model_merged_per_sentiment\")\n",
    "# fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hoverinfo": "text",
         "hovertext": [
          "<b>Topic Automation Components</b><br>Words: technical support, customer service, reliability, reliable, equipment<br>Percentage: 36.17%",
          "<b>Topic Automation Components</b><br>Words: technical support, programmable logic controller, service, technical, remotely<br>Percentage: 25.0%",
          "<b>Topic Automation Components</b><br>Words: rate, technical support, siemens, products, technical<br>Percentage: 11.11%",
          "<b>Topic Automation Components</b><br>Words: products, manufacture, product, factories, suppliers<br>Percentage: 30.77%",
          "<b>Topic Automation Components</b><br>Words: technical support, customer service, repair, equipment, service<br>Percentage: 16.05%",
          "<b>Topic Automation Components</b><br>Words: electric, servo, metering, customer service, problems<br>Percentage: 26.67%",
          "<b>Topic Automation Components</b><br>Words: touch panel, pfxgp4401tad, font, programmable, software<br>Percentage: 11.11%",
          "<b>Topic Automation Components</b><br>Words: technical support, switchboards, quality, motors, zb5<br>Percentage: 23.08%",
          "<b>Topic Automation Components</b><br>Words: suppliers, supplier, distributor, warranty, parts<br>Percentage: 66.67%",
          "<b>Topic Automation Components</b><br>Words: products, websites, brand, product, equipment<br>Percentage: 20.0%",
          "<b>Topic Automation Components</b><br>Words: reliability, technology, inverter, inverters, servo<br>Percentage: 34.09%",
          "<b>Topic Automation Components</b><br>Words: servo motors, servo, motors, control, hardware<br>Percentage: 31.82%",
          "<b>Topic Automation Components</b><br>Words: technical support, programmable logic controller, unity, programmable, controller<br>Percentage: 40.08%",
          "<b>Topic Automation Components</b><br>Words: technical support, products, sales service, updates, product line<br>Percentage: 16.42%",
          "<b>Topic Automation Components</b><br>Words: technical support, siemens, inverter, inverters, warranty<br>Percentage: 45.9%",
          "<b>Topic Automation Components</b><br>Words: technical support, equipment, products, sales, inverters<br>Percentage: 35.92%",
          "<b>Topic Automation Components</b><br>Words: technical support, electric, controllers, technical, contractor<br>Percentage: 44.44%",
          "<b>Topic Automation Components</b><br>Words: servo motors, servo, programmable logic controller, technical support, motors<br>Percentage: 26.86%",
          "<b>Topic Automation Components</b><br>Words: electric, products, customer service, contactors, company<br>Percentage: 57.24%",
          "<b>Topic Automation Components</b><br>Words: software, inverters, components, customer service, consultant<br>Percentage: 50.0%",
          "<b>Topic Automation Components</b><br>Words: siemens, electric, breakers, prices, customer support<br>Percentage: 23.08%",
          "<b>Topic Automation Components</b><br>Words: technical support, siemens, switches, servo, technical<br>Percentage: 25.54%",
          "<b>Topic Automation Components</b><br>Words: products, pricing, components, catalog, touch panel<br>Percentage: 39.13%",
          "<b>Topic Automation Components</b><br>Words: programmable logic controller, programmable, controller, designing, programming<br>Percentage: 59.18%"
         ],
         "marker": {
          "color": "#E69F00"
         },
         "name": "Automation Components",
         "orientation": "h",
         "type": "bar",
         "visible": true,
         "x": [
          36.17,
          25,
          11.11,
          30.77,
          16.05,
          26.67,
          11.11,
          23.08,
          66.67,
          20,
          34.09,
          31.82,
          40.08,
          16.42,
          45.9,
          35.92,
          44.44,
          26.86,
          57.24,
          50,
          23.08,
          25.54,
          39.13,
          59.18
         ],
         "y": [
          "admiration",
          "amusement",
          "excitement",
          "sadness",
          "gratitude",
          "annoyance",
          "nervousness",
          "fear",
          "embarrassment",
          "disgust",
          "curiosity",
          "realization",
          "disapproval",
          "caring",
          "optimism",
          "approval",
          "desire",
          "disappointment",
          "joy",
          "remorse",
          "surprise",
          "neutral",
          "confusion",
          "love"
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "<b>Topic Technical Support</b><br>Words: technical support, customer service, technicians, technical, technician<br>Percentage: 29.35%",
          "<b>Topic Technical Support</b><br>Words: enthusiastic, technical support, technical, tech, technicians<br>Percentage: 44.44%",
          "<b>Topic Technical Support</b><br>Words: miserable, administration, breaker, technical support, painful<br>Percentage: 15.38%",
          "<b>Topic Technical Support</b><br>Words: technical support, customer service, technician, technicians, contact<br>Percentage: 29.9%",
          "<b>Topic Technical Support</b><br>Words: customer service, communicate, annoyance, telephone, polite<br>Percentage: 16.19%",
          "<b>Topic Technical Support</b><br>Words: response time, communication, response, quick response, chat<br>Percentage: 44.44%",
          "<b>Topic Technical Support</b><br>Words: technical support, responsiveness, resources, assistance, requests<br>Percentage: 7.69%",
          "<b>Topic Technical Support</b><br>Words: response time, email, mail, receiving, response<br>Percentage: 15.91%",
          "<b>Topic Technical Support</b><br>Words: information, contents, page, assistance, brake<br>Percentage: 9.09%",
          "<b>Topic Technical Support</b><br>Words: technical support, response time, recalled, assistance, call back<br>Percentage: 11.09%",
          "<b>Topic Technical Support</b><br>Words: technical support, support, assistance, consultation, response time<br>Percentage: 44.03%",
          "<b>Topic Technical Support</b><br>Words: technical support, contact, technical, technician, technology<br>Percentage: 13.11%",
          "<b>Topic Technical Support</b><br>Words: technical support, response time, technical, support, technician<br>Percentage: 17.01%",
          "<b>Topic Technical Support</b><br>Words: checkpoints, feedback, complaints, responding, responded<br>Percentage: 14.14%",
          "<b>Topic Technical Support</b><br>Words: technical support, messages, technician, technical, assistance<br>Percentage: 9.95%",
          "<b>Topic Technical Support</b><br>Words: telephone, service, call, technical support, monitoring<br>Percentage: 12.79%",
          "<b>Topic Technical Support</b><br>Words: support, technical support, response time, response, email<br>Percentage: 10.0%",
          "<b>Topic Technical Support</b><br>Words: courtesy, customer service, call back, telephone, polite<br>Percentage: 15.38%",
          "<b>Topic Technical Support</b><br>Words: response time, technical support, responses, customer service, technician<br>Percentage: 26.37%",
          "<b>Topic Technical Support</b><br>Words: assignment, technical support, individual, inconsistency, issues<br>Percentage: 12.73%",
          "<b>Topic Technical Support</b><br>Words: service, customer service, support, friendliness, health<br>Percentage: 12.24%",
          "<b>Topic Technical Support</b><br>Words: questions, stupid, stop, question, inquiry<br>Percentage: 100.0%"
         ],
         "marker": {
          "color": "#56B4E9"
         },
         "name": "Technical Support",
         "orientation": "h",
         "type": "bar",
         "visible": "legendonly",
         "x": [
          29.35,
          44.44,
          15.38,
          29.9,
          16.19,
          44.44,
          7.69,
          15.91,
          9.09,
          11.09,
          44.03,
          13.11,
          17.01,
          14.14,
          9.95,
          12.79,
          10,
          15.38,
          26.37,
          12.73,
          12.24,
          100
         ],
         "y": [
          "admiration",
          "excitement",
          "sadness",
          "gratitude",
          "annoyance",
          "nervousness",
          "fear",
          "curiosity",
          "realization",
          "disapproval",
          "caring",
          "optimism",
          "approval",
          "desire",
          "disappointment",
          "joy",
          "remorse",
          "surprise",
          "neutral",
          "confusion",
          "love",
          "anger"
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "<b>Topic Delivery Deadlines</b><br>Words: deliveries, delivery time, delivery, delays, delivery date<br>Percentage: 6.84%",
          "<b>Topic Delivery Deadlines</b><br>Words: delivery time, deliveries, delivery, delivery date, deliver<br>Percentage: 50.0%",
          "<b>Topic Delivery Deadlines</b><br>Words: delivery time, delivery date, delivery, deliveries, deliver<br>Percentage: 22.22%",
          "<b>Topic Delivery Deadlines</b><br>Words: shipment, deliveries, missing, boxes, delivery<br>Percentage: 30.77%",
          "<b>Topic Delivery Deadlines</b><br>Words: delivery date, deliveries, delivery time, delivery, shipping<br>Percentage: 12.37%",
          "<b>Topic Delivery Deadlines</b><br>Words: delivery time, delivery date, delays, deliveries, delivery<br>Percentage: 38.1%",
          "<b>Topic Delivery Deadlines</b><br>Words: delivery time, deliveries, delivery date, delivery, delays<br>Percentage: 22.22%",
          "<b>Topic Delivery Deadlines</b><br>Words: delivery time, deliveries, delivery, sales service, orders<br>Percentage: 61.54%",
          "<b>Topic Delivery Deadlines</b><br>Words: courier, brt, deliveries, delivery time, delivery<br>Percentage: 16.67%",
          "<b>Topic Delivery Deadlines</b><br>Words: delivery time, deliveries, delivery date, delivery, delays<br>Percentage: 40.0%",
          "<b>Topic Delivery Deadlines</b><br>Words: deliveries, delivery, invoice, arrives, envelope<br>Percentage: 20.45%",
          "<b>Topic Delivery Deadlines</b><br>Words: delivery date, delivery, orders, order, scheduled<br>Percentage: 27.27%",
          "<b>Topic Delivery Deadlines</b><br>Words: delivery time, delivery date, deliveries, delivery, deliver<br>Percentage: 21.01%",
          "<b>Topic Delivery Deadlines</b><br>Words: delivery time, deliveries, delivery, logistics, packaging<br>Percentage: 11.19%",
          "<b>Topic Delivery Deadlines</b><br>Words: delivery time, delays, delivery date, delayed, deliveries<br>Percentage: 19.67%",
          "<b>Topic Delivery Deadlines</b><br>Words: delivery time, deliveries, delivery date, delivery, invoice<br>Percentage: 13.51%",
          "<b>Topic Delivery Deadlines</b><br>Words: delivery time, deliveries, delivery date, delivery, shipping<br>Percentage: 16.16%",
          "<b>Topic Delivery Deadlines</b><br>Words: delivery time, delivery date, deliveries, delivery, delays<br>Percentage: 42.69%",
          "<b>Topic Delivery Deadlines</b><br>Words: delivery time, deliveries, delivery, delivery date, delays<br>Percentage: 10.77%",
          "<b>Topic Delivery Deadlines</b><br>Words: delivery time, delivery, deliveries, shipping, delivered<br>Percentage: 25.0%",
          "<b>Topic Delivery Deadlines</b><br>Words: delivery time, delivery date, deliveries, delivery, arrive<br>Percentage: 23.08%",
          "<b>Topic Delivery Deadlines</b><br>Words: delivery date, delivery time, deliveries, delivery, delays<br>Percentage: 25.88%",
          "<b>Topic Delivery Deadlines</b><br>Words: deliveries, delivery time, delivery, shipping, delivery date<br>Percentage: 24.84%",
          "<b>Topic Delivery Deadlines</b><br>Words: feedback, deliveries, delivery date, delivery, delivery time<br>Percentage: 4.08%"
         ],
         "marker": {
          "color": "#009E73"
         },
         "name": "Delivery Deadlines",
         "orientation": "h",
         "type": "bar",
         "visible": "legendonly",
         "x": [
          6.84,
          50,
          22.22,
          30.77,
          12.37,
          38.1,
          22.22,
          61.54,
          16.67,
          40,
          20.45,
          27.27,
          21.01,
          11.19,
          19.67,
          13.51,
          16.16,
          42.69,
          10.77,
          25,
          23.08,
          25.88,
          24.84,
          4.08
         ],
         "y": [
          "admiration",
          "amusement",
          "excitement",
          "sadness",
          "gratitude",
          "annoyance",
          "nervousness",
          "fear",
          "embarrassment",
          "disgust",
          "curiosity",
          "realization",
          "disapproval",
          "caring",
          "optimism",
          "approval",
          "desire",
          "disappointment",
          "joy",
          "remorse",
          "surprise",
          "neutral",
          "confusion",
          "love"
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "<b>Topic Problem Solving & Comm</b><br>Words: polite, politely, manner, pleased, replying<br>Percentage: 1.25%",
          "<b>Topic Problem Solving & Comm</b><br>Words: merry, christmas, inquiries, questions, asked<br>Percentage: 11.11%",
          "<b>Topic Problem Solving & Comm</b><br>Words: inquiries, polite, responded, contacted, response<br>Percentage: 10.6%",
          "<b>Topic Problem Solving & Comm</b><br>Words: stop, questions, respond, asked, answered<br>Percentage: 0.95%",
          "<b>Topic Problem Solving & Comm</b><br>Words: inquiries, inquiry, questions, inquired, answers<br>Percentage: 2.27%",
          "<b>Topic Problem Solving & Comm</b><br>Words: promptly, immediate, immediately, realization, solutions<br>Percentage: 9.09%",
          "<b>Topic Problem Solving & Comm</b><br>Words: incomplete, inadequate, solutions, feedback, inquiry<br>Percentage: 1.95%",
          "<b>Topic Problem Solving & Comm</b><br>Words: problem, solutions, solve problem, patiently, solution<br>Percentage: 5.97%",
          "<b>Topic Problem Solving & Comm</b><br>Words: accurately, accurate, solve problem, answers, solutions<br>Percentage: 0.82%",
          "<b>Topic Problem Solving & Comm</b><br>Words: inquiry, answered, straightforward, answers, polite<br>Percentage: 11.53%",
          "<b>Topic Problem Solving & Comm</b><br>Words: inquiries, respond, inquiry, response, communication<br>Percentage: 4.04%",
          "<b>Topic Problem Solving & Comm</b><br>Words: inquiry, answered, clarified, explained, response<br>Percentage: 1.44%",
          "<b>Topic Problem Solving & Comm</b><br>Words: response, inquiries, sincerely, responded, respond<br>Percentage: 3.37%",
          "<b>Topic Problem Solving & Comm</b><br>Words: shape, model, accurately, answers, precise<br>Percentage: 7.69%",
          "<b>Topic Problem Solving & Comm</b><br>Words: answers, answered, answer, quick response, explained<br>Percentage: 5.18%",
          "<b>Topic Problem Solving & Comm</b><br>Words: answers, unclear, answered, clear, response<br>Percentage: 3.73%"
         ],
         "marker": {
          "color": "#F0E442"
         },
         "name": "Problem Solving & Comm",
         "orientation": "h",
         "type": "bar",
         "visible": "legendonly",
         "x": [
          1.25,
          11.11,
          10.6,
          0.95,
          2.27,
          9.09,
          1.95,
          5.97,
          0.82,
          11.53,
          4.04,
          1.44,
          3.37,
          7.69,
          5.18,
          3.73
         ],
         "y": [
          "admiration",
          "excitement",
          "gratitude",
          "annoyance",
          "curiosity",
          "realization",
          "disapproval",
          "caring",
          "optimism",
          "approval",
          "desire",
          "disappointment",
          "joy",
          "surprise",
          "neutral",
          "confusion"
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "<b>Topic Power Supply Issues</b><br>Words: ups, uninterruptible power supply, power supply, reliability, warranty<br>Percentage: 1.99%",
          "<b>Topic Power Supply Issues</b><br>Words: batteries, battery, ups, replaced, uninterruptible power supply<br>Percentage: 11.11%",
          "<b>Topic Power Supply Issues</b><br>Words: recovered, repair, broken, licenses, failure<br>Percentage: 7.69%",
          "<b>Topic Power Supply Issues</b><br>Words: ups, troubleshooting, uninterruptible power supply, repair, troubleshoot<br>Percentage: 13.25%",
          "<b>Topic Power Supply Issues</b><br>Words: troubleshooting, troubleshoot, complaint, ups, repair<br>Percentage: 3.81%",
          "<b>Topic Power Supply Issues</b><br>Words: error, troubleshooting, agency, fault, damages<br>Percentage: 16.67%",
          "<b>Topic Power Supply Issues</b><br>Words: warranty, repaired, maintenance, repair, fuse<br>Percentage: 9.09%",
          "<b>Topic Power Supply Issues</b><br>Words: resolved, error, vfd, hp, solution<br>Percentage: 13.64%",
          "<b>Topic Power Supply Issues</b><br>Words: maintenance, repair, warranty, battery, faulty<br>Percentage: 5.84%",
          "<b>Topic Power Supply Issues</b><br>Words: repair, troubleshooting, repairs, technical support, defective<br>Percentage: 5.97%",
          "<b>Topic Power Supply Issues</b><br>Words: repair, ups, complaint, defects, apc<br>Percentage: 4.51%",
          "<b>Topic Power Supply Issues</b><br>Words: ups, uninterruptible power supply, maintenance, technical support, batteries<br>Percentage: 5.43%",
          "<b>Topic Power Supply Issues</b><br>Words: faulty, issue, error, ups5000, fix<br>Percentage: 8.08%",
          "<b>Topic Power Supply Issues</b><br>Words: ups, technical support, uninterruptible power supply, troubleshooting, power supply<br>Percentage: 7.91%",
          "<b>Topic Power Supply Issues</b><br>Words: complaint, faulty, resolved, issue, components<br>Percentage: 2.69%",
          "<b>Topic Power Supply Issues</b><br>Words: troubleshooting, issue, error, repair, problem<br>Percentage: 15.0%",
          "<b>Topic Power Supply Issues</b><br>Words: xvsv7bbn, uninterruptible power supply, troubleshooting, audio, ups<br>Percentage: 7.69%",
          "<b>Topic Power Supply Issues</b><br>Words: ups, warranty, uninterruptible power supply, apc, technical support<br>Percentage: 4.78%",
          "<b>Topic Power Supply Issues</b><br>Words: ups, uninterruptible power supply, warranty, repair, apc<br>Percentage: 6.52%",
          "<b>Topic Power Supply Issues</b><br>Words: apc, ups, uninterruptible power supply, technical support, products<br>Percentage: 4.08%",
          "<b>Topic Power Supply Issues</b><br>Words: troubleshooting, technical support, support, resolved, repair<br>Percentage: 100.0%"
         ],
         "marker": {
          "color": "#D55E00"
         },
         "name": "Power Supply Issues",
         "orientation": "h",
         "type": "bar",
         "visible": "legendonly",
         "x": [
          1.99,
          11.11,
          7.69,
          13.25,
          3.81,
          16.67,
          9.09,
          13.64,
          5.84,
          5.97,
          4.51,
          5.43,
          8.08,
          7.91,
          2.69,
          15,
          7.69,
          4.78,
          6.52,
          4.08,
          100
         ],
         "y": [
          "admiration",
          "excitement",
          "sadness",
          "gratitude",
          "annoyance",
          "embarrassment",
          "curiosity",
          "realization",
          "disapproval",
          "caring",
          "optimism",
          "approval",
          "desire",
          "disappointment",
          "joy",
          "remorse",
          "surprise",
          "neutral",
          "confusion",
          "love",
          "relief"
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "<b>Topic Customer Support</b><br>Words: technical support, technical service, customer service, reliable, reliability<br>Percentage: 8.45%",
          "<b>Topic Customer Support</b><br>Words: customer service, technical support, customers, reliable, manufacturers<br>Percentage: 1.62%",
          "<b>Topic Customer Support</b><br>Words: quality, reliability, reliable, materials, availability<br>Percentage: 0.95%",
          "<b>Topic Customer Support</b><br>Words: technical support, reliability, reliable, quality, supports<br>Percentage: 3.5%",
          "<b>Topic Customer Support</b><br>Words: cooperation, feedback, fine, technical support, issues<br>Percentage: 2.24%",
          "<b>Topic Customer Support</b><br>Words: reliable, reliability, quality, technical support, stable<br>Percentage: 2.46%",
          "<b>Topic Customer Support</b><br>Words: reliable, technical support, reliability, products, quality<br>Percentage: 7.24%",
          "<b>Topic Customer Support</b><br>Words: technical support, promotional, sales, products, customers<br>Percentage: 1.01%",
          "<b>Topic Customer Support</b><br>Words: reliability, reliable, technical support, quality, technology<br>Percentage: 1.44%",
          "<b>Topic Customer Support</b><br>Words: technical support, service support, technical service, reliability, support<br>Percentage: 5.05%",
          "<b>Topic Customer Support</b><br>Words: technical support, quality, customer service, reliability, services<br>Percentage: 1.99%",
          "<b>Topic Customer Support</b><br>Words: reliability, reliable, technical support, products, product<br>Percentage: 0.93%",
          "<b>Topic Customer Support</b><br>Words: reliable, quality, reliability, product, products<br>Percentage: 10.2%"
         ],
         "marker": {
          "color": "#0072B2"
         },
         "name": "Customer Support",
         "orientation": "h",
         "type": "bar",
         "visible": "legendonly",
         "x": [
          8.45,
          1.62,
          0.95,
          3.5,
          2.24,
          2.46,
          7.24,
          1.01,
          1.44,
          5.05,
          1.99,
          0.93,
          10.2
         ],
         "y": [
          "admiration",
          "gratitude",
          "annoyance",
          "disapproval",
          "caring",
          "optimism",
          "approval",
          "desire",
          "disappointment",
          "joy",
          "neutral",
          "confusion",
          "love"
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "<b>Topic Product Evaluation</b><br>Words: rating, quality, reliability, performance, pricing<br>Percentage: 7.22%",
          "<b>Topic Product Evaluation</b><br>Words: zero, qa, rating, certification, score<br>Percentage: 25.0%",
          "<b>Topic Product Evaluation</b><br>Words: rating, ratings, quality, performance, pricing<br>Percentage: 1.03%",
          "<b>Topic Product Evaluation</b><br>Words: performance, rating, improvement, quality, pricing<br>Percentage: 1.9%",
          "<b>Topic Product Evaluation</b><br>Words: prices, pricing, bad, discounts, price<br>Percentage: 20.0%",
          "<b>Topic Product Evaluation</b><br>Words: oil, prices, quality, cost, pricing<br>Percentage: 4.55%",
          "<b>Topic Product Evaluation</b><br>Words: rating, quality, rate, feedback, sales<br>Percentage: 6.23%",
          "<b>Topic Product Evaluation</b><br>Words: products, efficiency, customer service, sales, performance<br>Percentage: 0.75%",
          "<b>Topic Product Evaluation</b><br>Words: rating, prices, performance, review, technical support<br>Percentage: 6.15%",
          "<b>Topic Product Evaluation</b><br>Words: rating, pricing, quality, prices, affordable<br>Percentage: 3.65%",
          "<b>Topic Product Evaluation</b><br>Words: quality, products, pricing, product, rating<br>Percentage: 5.05%",
          "<b>Topic Product Evaluation</b><br>Words: rating, quality, evaluated, performance, score<br>Percentage: 2.16%",
          "<b>Topic Product Evaluation</b><br>Words: pricing, customer support, quality, prices, satisfactory<br>Percentage: 4.71%",
          "<b>Topic Product Evaluation</b><br>Words: rating, performance, quality, reliability, score<br>Percentage: 2.14%",
          "<b>Topic Product Evaluation</b><br>Words: quality, pricing, rating, rate, evaluation<br>Percentage: 2.8%",
          "<b>Topic Product Evaluation</b><br>Words: products, product, manufacturers, quality, overall<br>Percentage: 8.16%"
         ],
         "marker": {
          "color": "#CC79A7"
         },
         "name": "Product Evaluation",
         "orientation": "h",
         "type": "bar",
         "visible": "legendonly",
         "x": [
          7.22,
          25,
          1.03,
          1.9,
          20,
          4.55,
          6.23,
          0.75,
          6.15,
          3.65,
          5.05,
          2.16,
          4.71,
          2.14,
          2.8,
          8.16
         ],
         "y": [
          "admiration",
          "amusement",
          "gratitude",
          "annoyance",
          "disgust",
          "realization",
          "disapproval",
          "caring",
          "optimism",
          "approval",
          "desire",
          "disappointment",
          "joy",
          "neutral",
          "confusion",
          "love"
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "<b>Topic Pricing</b><br>Words: quotes, quotation, quotations, response time, pricing<br>Percentage: 1.04%",
          "<b>Topic Pricing</b><br>Words: quotation, text, payment, order, ordering<br>Percentage: 1.62%",
          "<b>Topic Pricing</b><br>Words: pricing, invoice, orders, prices, order<br>Percentage: 6.67%",
          "<b>Topic Pricing</b><br>Words: pricing, prices, price, catalog, negotiate<br>Percentage: 9.09%",
          "<b>Topic Pricing</b><br>Words: covd, orders, order, promptly, staffing<br>Percentage: 4.55%",
          "<b>Topic Pricing</b><br>Words: quotations, quotation, emails, send, bidding<br>Percentage: 4.86%",
          "<b>Topic Pricing</b><br>Words: quotations, quotes, quotation, received, contact<br>Percentage: 2.24%",
          "<b>Topic Pricing</b><br>Words: invoices, invoice, payment, purchase, pricing<br>Percentage: 1.64%",
          "<b>Topic Pricing</b><br>Words: invoices, invoice, invoiced, pricing, payment<br>Percentage: 1.31%",
          "<b>Topic Pricing</b><br>Words: invoices, invoice, customer support, payment, delivery date<br>Percentage: 3.0%",
          "<b>Topic Pricing</b><br>Words: response time, delay, quotations, quotation, quotes<br>Percentage: 0.67%",
          "<b>Topic Pricing</b><br>Words: pricing, prices, price, discount, increase<br>Percentage: 11.54%",
          "<b>Topic Pricing</b><br>Words: pricing, prices, discount, price, invoice<br>Percentage: 3.48%",
          "<b>Topic Pricing</b><br>Words: quotation, quote, response time, replying, response<br>Percentage: 4.66%"
         ],
         "marker": {
          "color": "#E69F00"
         },
         "name": "Pricing",
         "orientation": "h",
         "type": "bar",
         "visible": "legendonly",
         "x": [
          1.04,
          1.62,
          6.67,
          9.09,
          4.55,
          4.86,
          2.24,
          1.64,
          1.31,
          3,
          0.67,
          11.54,
          3.48,
          4.66
         ],
         "y": [
          "admiration",
          "gratitude",
          "annoyance",
          "curiosity",
          "realization",
          "disapproval",
          "caring",
          "optimism",
          "approval",
          "disappointment",
          "joy",
          "surprise",
          "neutral",
          "confusion"
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "<b>Topic Assistance</b><br>Words: responsiveness, responsively, responsive, effective, effectiveness<br>Percentage: 2.29%",
          "<b>Topic Assistance</b><br>Words: assisted, assistance, helped, helpful, help<br>Percentage: 7.69%",
          "<b>Topic Assistance</b><br>Words: responsiveness, responsively, timely, rapid, quickly<br>Percentage: 2.36%",
          "<b>Topic Assistance</b><br>Words: feedback, lack, responsiveness, quality, response<br>Percentage: 0.95%",
          "<b>Topic Assistance</b><br>Words: response time, feedback, processing, speed, commitment<br>Percentage: 0.39%",
          "<b>Topic Assistance</b><br>Words: helped, assistance, helpful, timely, quickly<br>Percentage: 10.45%",
          "<b>Topic Assistance</b><br>Words: carpentry, efficient, efficiency, fast, rapid<br>Percentage: 0.41%",
          "<b>Topic Assistance</b><br>Words: advice, guidance, advise, competent, competently<br>Percentage: 1.72%",
          "<b>Topic Assistance</b><br>Words: flexible, responsively, responsiveness, want, responsive<br>Percentage: 1.01%",
          "<b>Topic Assistance</b><br>Words: responsiveness, feedback, responsively, responsive, slow<br>Percentage: 0.72%",
          "<b>Topic Assistance</b><br>Words: timely, unexpected, quickly, assistance, immediate<br>Percentage: 3.85%",
          "<b>Topic Assistance</b><br>Words: feedback, responsiveness, responsive, efficiently, accuracy<br>Percentage: 1.72%"
         ],
         "marker": {
          "color": "#56B4E9"
         },
         "name": "Assistance",
         "orientation": "h",
         "type": "bar",
         "visible": "legendonly",
         "x": [
          2.29,
          7.69,
          2.36,
          0.95,
          0.39,
          10.45,
          0.41,
          1.72,
          1.01,
          0.72,
          3.85,
          1.72
         ],
         "y": [
          "admiration",
          "sadness",
          "gratitude",
          "annoyance",
          "disapproval",
          "caring",
          "optimism",
          "approval",
          "desire",
          "disappointment",
          "surprise",
          "neutral"
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "<b>Topic Touch Screens</b><br>Words: siemens, bpx, tsx, companies, displays<br>Percentage: 0.63%",
          "<b>Topic Touch Screens</b><br>Words: pfxpu2bdcd8bj0nn00, sp5000, connect, sequencer, proface<br>Percentage: 7.69%",
          "<b>Topic Touch Screens</b><br>Words: pfxgp4301tad, pfxgp4501tad, gp4300, gp4000, gpproex<br>Percentage: 0.59%",
          "<b>Topic Touch Screens</b><br>Words: invoices, invoicing, siemens, touch panel, certificates<br>Percentage: 1.9%",
          "<b>Topic Touch Screens</b><br>Words: gp2501, propb3, gpproex, touch panel, touch screen<br>Percentage: 22.22%",
          "<b>Topic Touch Screens</b><br>Words: plc, touch panel, siemens, panel, lamp<br>Percentage: 7.69%",
          "<b>Topic Touch Screens</b><br>Words: screen, touch screen, outdated, screens, indecent<br>Percentage: 20.0%",
          "<b>Topic Touch Screens</b><br>Words: catalogue, backplates, costs, siemens, cabinets<br>Percentage: 6.82%",
          "<b>Topic Touch Screens</b><br>Words: oem, technical support, siemens, software, usability<br>Percentage: 2.53%",
          "<b>Topic Touch Screens</b><br>Words: siemens, companies, ab, greedy, manufacturers<br>Percentage: 0.75%",
          "<b>Topic Touch Screens</b><br>Words: gp430, gp4301, touch screen, touch panel, gp4000<br>Percentage: 4.51%",
          "<b>Topic Touch Screens</b><br>Words: displays, touch screen, screens, touch panel, gp4000<br>Percentage: 1.17%",
          "<b>Topic Touch Screens</b><br>Words: touch screen, touch panel, screen, screens, datasheets<br>Percentage: 6.06%",
          "<b>Topic Touch Screens</b><br>Words: touch panel, touch screen, panel, reliability, touch<br>Percentage: 1.08%",
          "<b>Topic Touch Screens</b><br>Words: touch panel, touch screen, displays, screens, gp4000<br>Percentage: 1.01%",
          "<b>Topic Touch Screens</b><br>Words: touch panel, manufacturers, touch screen, manufacturer, siemens<br>Percentage: 1.67%",
          "<b>Topic Touch Screens</b><br>Words: touch panel, firmware, merger, manufacturers, contact person<br>Percentage: 2.17%"
         ],
         "marker": {
          "color": "#009E73"
         },
         "name": "Touch Screens",
         "orientation": "h",
         "type": "bar",
         "visible": "legendonly",
         "x": [
          0.63,
          7.69,
          0.59,
          1.9,
          22.22,
          7.69,
          20,
          6.82,
          2.53,
          0.75,
          4.51,
          1.17,
          6.06,
          1.08,
          1.01,
          1.67,
          2.17
         ],
         "y": [
          "admiration",
          "sadness",
          "gratitude",
          "annoyance",
          "nervousness",
          "fear",
          "disgust",
          "curiosity",
          "disapproval",
          "caring",
          "optimism",
          "approval",
          "desire",
          "disappointment",
          "joy",
          "neutral",
          "confusion"
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "<b>Topic Frequency Converters</b><br>Words: frequency converters, converters, customer support, converter, customer service<br>Percentage: 1.5%",
          "<b>Topic Frequency Converters</b><br>Words: frequency converters, converters, converter, frequency, hz<br>Percentage: 0.88%",
          "<b>Topic Frequency Converters</b><br>Words: frequency converters, technical support, customer service, converters, reliability<br>Percentage: 1.9%",
          "<b>Topic Frequency Converters</b><br>Words: frequency converters, converters, frequency, converter, reason<br>Percentage: 2.27%",
          "<b>Topic Frequency Converters</b><br>Words: frequency converters, converters, frequency, fuses, equipment<br>Percentage: 2.53%",
          "<b>Topic Frequency Converters</b><br>Words: frequency converters, frequency, converters, converter, noisy<br>Percentage: 0.82%",
          "<b>Topic Frequency Converters</b><br>Words: frequency converters, contactors, technical support, converters, customer support<br>Percentage: 1.52%",
          "<b>Topic Frequency Converters</b><br>Words: frequency converters, converters, frequency, customer service, availability<br>Percentage: 2.76%",
          "<b>Topic Frequency Converters</b><br>Words: frequency converters, converters, converter, frequency, quality<br>Percentage: 1.68%",
          "<b>Topic Frequency Converters</b><br>Words: frequency converters, frequency, manufacturers, converters, complaints<br>Percentage: 7.69%",
          "<b>Topic Frequency Converters</b><br>Words: frequency converters, converters, converter, frequency, technical support<br>Percentage: 0.74%",
          "<b>Topic Frequency Converters</b><br>Words: frequency converters, frequency, converters, performance, drivers<br>Percentage: 2.48%",
          "<b>Topic Frequency Converters</b><br>Words: frequency converters, electrical, electric, converters, converter<br>Percentage: 2.04%"
         ],
         "marker": {
          "color": "#F0E442"
         },
         "name": "Frequency Converters",
         "orientation": "h",
         "type": "bar",
         "visible": "legendonly",
         "x": [
          1.5,
          0.88,
          1.9,
          2.27,
          2.53,
          0.82,
          1.52,
          2.76,
          1.68,
          7.69,
          0.74,
          2.48,
          2.04
         ],
         "y": [
          "admiration",
          "gratitude",
          "annoyance",
          "curiosity",
          "disapproval",
          "optimism",
          "approval",
          "disappointment",
          "joy",
          "surprise",
          "neutral",
          "confusion",
          "love"
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "<b>Topic Positive feedback</b><br>Words: service, excellent, appreciate, welcome, helpful<br>Percentage: 3.22%",
          "<b>Topic Positive feedback</b><br>Words: service, welcome, appreciate, excellent, helpful<br>Percentage: 2.36%"
         ],
         "marker": {
          "color": "#D55E00"
         },
         "name": "Positive feedback",
         "orientation": "h",
         "type": "bar",
         "visible": "legendonly",
         "x": [
          3.22,
          2.36
         ],
         "y": [
          "admiration",
          "gratitude"
         ]
        },
        {
         "hoverinfo": "text",
         "hovertext": [
          "<b>Topic Quick Customer Service</b><br>Words: quick response, quick, response, appreciate, fast<br>Percentage: 0.05%",
          "<b>Topic Quick Customer Service</b><br>Words: quick response, quick, response, quicker, regards<br>Percentage: 7.36%",
          "<b>Topic Quick Customer Service</b><br>Words: quick response, response, quick, short, reply<br>Percentage: 0.53%"
         ],
         "marker": {
          "color": "#0072B2"
         },
         "name": "Quick Customer Service",
         "orientation": "h",
         "type": "bar",
         "visible": "legendonly",
         "x": [
          0.05,
          7.36,
          0.53
         ],
         "y": [
          "admiration",
          "gratitude",
          "neutral"
         ]
        }
       ],
       "layout": {
        "barmode": "stack",
        "height": 750,
        "hoverlabel": {
         "bgcolor": "white",
         "font": {
          "family": "Rockwell",
          "size": 16
         }
        },
        "legend": {
         "title": {
          "text": "<b>Global Topic Representation"
         }
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "rgb(36,36,36)"
            },
            "error_y": {
             "color": "rgb(36,36,36)"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "rgb(36,36,36)",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "rgb(36,36,36)"
            },
            "baxis": {
             "endlinecolor": "rgb(36,36,36)",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "rgb(36,36,36)"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.6
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "rgb(237,237,237)"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "rgb(217,217,217)"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 1,
            "tickcolor": "rgb(36,36,36)",
            "ticks": "outside"
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "rgb(103,0,31)"
            ],
            [
             0.1,
             "rgb(178,24,43)"
            ],
            [
             0.2,
             "rgb(214,96,77)"
            ],
            [
             0.3,
             "rgb(244,165,130)"
            ],
            [
             0.4,
             "rgb(253,219,199)"
            ],
            [
             0.5,
             "rgb(247,247,247)"
            ],
            [
             0.6,
             "rgb(209,229,240)"
            ],
            [
             0.7,
             "rgb(146,197,222)"
            ],
            [
             0.8,
             "rgb(67,147,195)"
            ],
            [
             0.9,
             "rgb(33,102,172)"
            ],
            [
             1,
             "rgb(5,48,97)"
            ]
           ],
           "sequential": [
            [
             0,
             "#440154"
            ],
            [
             0.1111111111111111,
             "#482878"
            ],
            [
             0.2222222222222222,
             "#3e4989"
            ],
            [
             0.3333333333333333,
             "#31688e"
            ],
            [
             0.4444444444444444,
             "#26828e"
            ],
            [
             0.5555555555555556,
             "#1f9e89"
            ],
            [
             0.6666666666666666,
             "#35b779"
            ],
            [
             0.7777777777777778,
             "#6ece58"
            ],
            [
             0.8888888888888888,
             "#b5de2b"
            ],
            [
             1,
             "#fde725"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#440154"
            ],
            [
             0.1111111111111111,
             "#482878"
            ],
            [
             0.2222222222222222,
             "#3e4989"
            ],
            [
             0.3333333333333333,
             "#31688e"
            ],
            [
             0.4444444444444444,
             "#26828e"
            ],
            [
             0.5555555555555556,
             "#1f9e89"
            ],
            [
             0.6666666666666666,
             "#35b779"
            ],
            [
             0.7777777777777778,
             "#6ece58"
            ],
            [
             0.8888888888888888,
             "#b5de2b"
            ],
            [
             1,
             "#fde725"
            ]
           ]
          },
          "colorway": [
           "#1F77B4",
           "#FF7F0E",
           "#2CA02C",
           "#D62728",
           "#9467BD",
           "#8C564B",
           "#E377C2",
           "#7F7F7F",
           "#BCBD22",
           "#17BECF"
          ],
          "font": {
           "color": "rgb(36,36,36)"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "rgb(232,232,232)",
            "gridwidth": 2,
            "linecolor": "rgb(36,36,36)",
            "showbackground": true,
            "showgrid": false,
            "showline": true,
            "ticks": "outside",
            "zeroline": false,
            "zerolinecolor": "rgb(36,36,36)"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "rgb(232,232,232)",
            "gridwidth": 2,
            "linecolor": "rgb(36,36,36)",
            "showbackground": true,
            "showgrid": false,
            "showline": true,
            "ticks": "outside",
            "zeroline": false,
            "zerolinecolor": "rgb(36,36,36)"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "rgb(232,232,232)",
            "gridwidth": 2,
            "linecolor": "rgb(36,36,36)",
            "showbackground": true,
            "showgrid": false,
            "showline": true,
            "ticks": "outside",
            "zeroline": false,
            "zerolinecolor": "rgb(36,36,36)"
           }
          },
          "shapedefaults": {
           "fillcolor": "black",
           "line": {
            "width": 0
           },
           "opacity": 0.3
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           },
           "baxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "rgb(232,232,232)",
           "linecolor": "rgb(36,36,36)",
           "showgrid": false,
           "showline": true,
           "ticks": "outside",
           "title": {
            "standoff": 15
           },
           "zeroline": false,
           "zerolinecolor": "rgb(36,36,36)"
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "rgb(232,232,232)",
           "linecolor": "rgb(36,36,36)",
           "showgrid": false,
           "showline": true,
           "ticks": "outside",
           "title": {
            "standoff": 15
           },
           "zeroline": false,
           "zerolinecolor": "rgb(36,36,36)"
          }
         }
        },
        "title": {
         "font": {
          "color": "Black",
          "size": 22
         },
         "text": "Topics per Emotion",
         "x": 0.4,
         "xanchor": "center",
         "y": 0.95,
         "yanchor": "top"
        },
        "width": 1150,
        "xaxis": {
         "showgrid": true,
         "title": {
          "text": "Frequency"
         }
        },
        "yaxis": {
         "showgrid": true,
         "title": {
          "text": "Class"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Graph barchart topics by emotion\n",
    "\n",
    "# visualize the topic representation of major topics per Emotions (28 different emotions):\n",
    "fig = create_chart_per_class(df4, topic_model_merged, \"single_emotion_label\", \n",
    "                             custom_labels=True, \n",
    "                             percentage_by=None,\n",
    "                            #  stacked=True,\n",
    "                             title=\"Topics per Emotion\", \n",
    "                             width=1150, height=750)\n",
    "# Save the figure as an HTML file\n",
    "# save_graph_html(fig, \"../data/graphs/Sentiment_Analysis/by_emotion/repartition_per_topic/global\", \"model_merged_per_emotion\")\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Graph barchart topics by group\n",
    "\n",
    "# visualize the topic representation of major topics per group:\n",
    "group = \"Market Segment\"\n",
    "fig = create_chart_per_class(df4, topic_model_merged, group, \n",
    "                             custom_labels=True, \n",
    "                             use_percentage=False,\n",
    "                             title=f\"Topics per {group}\", \n",
    "                             width=1400, height=750)\n",
    "# Save the figure as an HTML file\n",
    "# save_graph_html(fig, f\"../data/graphs/Clustering/topic_repartition/by_{group}\", f\"model_merged_per_{group}\")\n",
    "# save_graph_html(fig, f\"../data/graphs/Clustering/topic_repartition/by_{group}\", f\"model_merged_per_{group}_pct\")\n",
    "# fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Graph barchart topics by \"by_class_name\" parameter for each value from \"subclass_names\"\n",
    "\n",
    "# Create a dictionary that match column name to a shorter name for saving name file\n",
    "shorter_names={\n",
    "    \"single_emotion_label\":\"emotion\",\n",
    "    \"sentiment_label\":\"sentiment\",\n",
    "    \"Market Segment\":\"market\",\n",
    "    \"Account Country\":\"country\",\n",
    "    \"Zone\":\"zone\",\n",
    "    \"Clusters\":\"cluster\",\n",
    "    \"year\":\"year\"\n",
    "}\n",
    "\n",
    "filter_group = \"single_emotion_label\"\n",
    "filter_group_shorter = shorter_names[filter_group]\n",
    "by_class_name = \"year\"\n",
    "# Loop for each value from the subclass\n",
    "for filter_value in df4[filter_group].unique() :\n",
    "    # visualize the topic representation of major topics per by_class_name for each value from subclass_name:\n",
    "    fig = create_chart_per_class(df4, topic_model_merged, by_class_name,\n",
    "                                filter=True, \n",
    "                                filter_group=filter_group, filter_value=filter_value, \n",
    "                                sortedBy=\"Frequency\",\n",
    "                                custom_labels=True, \n",
    "                                use_percentage=False,\n",
    "                                title=f\"Topics per {shorter_names[by_class_name]} - {filter_group_shorter}: {filter_value}\", \n",
    "                                width=1400, height=750)\n",
    "\n",
    "    # Save the figure as an HTML file\n",
    "    path = f\"../data/graphs/Sentiment_Analysis/by_emotion/repartition_per_topic/emotion_by_class/by_{by_class_name}\"\n",
    "    # save_graph_html(fig, path, filter_value)\n",
    "    # save_graph_html(fig, path, filter_value+\"_pct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_group = \"Market Segment\"\n",
    "filter_group_shorter = shorter_names[filter_group]\n",
    "by_class_name = \"single_emotion_label\"\n",
    "# Loop for each value from the subclass\n",
    "for filter_value in df4[filter_group].unique() :\n",
    "    # visualize the topic representation of major topics per by_class_name for each value from subclass_name:\n",
    "    fig = create_chart_per_class(df4, topic_model_merged, by_class_name,\n",
    "                                filter=True, \n",
    "                                filter_group=filter_group, filter_value=filter_value, \n",
    "                                sortedBy=\"Frequency\",\n",
    "                                custom_labels=True, \n",
    "                                use_percentage=False,\n",
    "                                title=f\"Topics per {shorter_names[by_class_name]} - {filter_group_shorter}: {filter_value}\", \n",
    "                                width=1400, height=750)\n",
    "\n",
    "    # Save the figure as an HTML file\n",
    "    path = f\"../data/graphs/Sentiment_Analysis/by_emotion/repartition_per_topic/class_by_emotions/by_{filter_group}\"\n",
    "    save_graph_html(fig, path, str(filter_value))\n",
    "    # save_graph_html(fig, path, str(filter_value)+\"_pct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Graph barchart for each topic with their top 5 keywords\n",
    "\n",
    "# create barchart for each of the top_n_topics best topics\n",
    "fig = topic_model.visualize_barchart(top_n_topics=12)\n",
    "# Save the figure as an HTML file\n",
    "# save_graph_html(fig, \"../data/graphs/Clustering/global\", \"top_12_topics_barchart_viz\")\n",
    "# fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [00:09<00:00,  6.50it/s]\n"
     ]
    }
   ],
   "source": [
    "### Graph hierarchical topics\n",
    "\n",
    "bertopic_model = topic_model\n",
    "hierarchical_topics = bertopic_model.hierarchical_topics(docs)\n",
    "fig = bertopic_model.visualize_hierarchy(hierarchical_topics=hierarchical_topics, custom_labels=True, width=1200, height=950)\n",
    "# Save the figure as an HTML file\n",
    "# save_graph_html(fig, \"../data/graphs/Clustering/hierarchy\", \"topics_hierarchy\")\n",
    "# fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Graph visualization of the documents in space\n",
    "\n",
    "# Run the visualization with the original embeddings\n",
    "topic_model_merged.visualize_documents(docs, embeddings=embeddings, custom_labels=True, hide_annotations=True)\n",
    "# Save the figure as an HTML file\n",
    "# save_graph_html(fig, \"../data/graphs/Clustering/documents_viz\", \"topic_merged_visualize_docs\")\n",
    "# fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Graph visualization of the documents after reducing embeddings in space\n",
    "\n",
    "# Reduce dimensionality of embeddings, this step is optional\n",
    "reduced_embeddings = UMAP(n_neighbors=10, n_components=2, min_dist=0.0, metric='cosine').fit_transform(embeddings)\n",
    "fig=topic_model_merged.visualize_documents(docs, reduced_embeddings=reduced_embeddings, custom_labels=True, hide_annotations=True)\n",
    "# Save the figure as an HTML file\n",
    "# save_graph_html(fig, \"../data/graphs/Clustering/documents_viz\", \"topic_merged_visualize_reduced_docs\")\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Graph visualization of the topics over time\n",
    "\n",
    "bertopic_model = topic_model_merged\n",
    "topics_over_time = bertopic_model.topics_over_time(docs, df4['year_month'])#, nr_bins=20)\n",
    "fig = bertopic_model.visualize_topics_over_time(topics_over_time, custom_labels=True)\n",
    "# Save the figure as an HTML file\n",
    "# save_graph_html(fig, \"../data/graphs/Clustering/topic_in_time\", \"topic_merged_time_by_months\")\n",
    "# fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Graph heatmap\n",
    "\n",
    "fig = topic_model_merged.visualize_heatmap(custom_labels=True, n_clusters=4, height=600)\n",
    "# Save the figure as an HTML file\n",
    "save_graph_html(fig, \"../data/graphs/Clustering/heatmap\", \"topic_merged_heatmap\")\n",
    "\n",
    "fig2 = topic_model.visualize_heatmap(n_clusters=8,  height=750)\n",
    "# Save the figure as an HTML file\n",
    "save_graph_html(fig2, \"../data/graphs/Clustering/heatmap\", \"topic_heatmap\")\n",
    "\n",
    "# fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Graph Visualize topics in 2D space\n",
    "\n",
    "fig = topic_model.visualize_topics()\n",
    "# Save the figure as an HTML file\n",
    "save_graph_html(fig, \"../data/graphs/Clustering/global\", \"topic_visualize_topics\")\n",
    "\n",
    "fig2 = topic_model_merged.visualize_topics()\n",
    "# Save the figure as an HTML file\n",
    "save_graph_html(fig2, \"../data/graphs/Clustering/global\", \"topic_merged_visualize_topics\")\n",
    "\n",
    "# fig2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Graph Topic distribution for one specific document\n",
    "\n",
    "topic_distr, topic_token_distr = topic_model_merged.approximate_distribution(docs, calculate_tokens=True)\n",
    "topic_model_merged.visualize_distribution(topic_distr[1], custom_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Graph Topic distribution by keywords for one specific document\n",
    "\n",
    "bertopic_model = topic_model_merged\n",
    "topic_distr, topic_token_distr = bertopic_model.approximate_distribution(docs, calculate_tokens=True, window=4)\n",
    "# # Visualize the token-level distributions\n",
    "bertopic_model.visualize_approximate_distribution(docs[1], topic_token_distr[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create the vocabulary using the OOP\n",
    "\n",
    "# import nltk\n",
    "# import sys\n",
    "# sys.path.insert(0, '..')\n",
    "# from utils import ngrams_list, more_stopwords, keybert_kwargs\n",
    "# from vocabulary.vocabulary import VocabularyCreator\n",
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# nltk.download('stopwords')\n",
    "# stopwords = nltk.corpus.stopwords.words('english')\n",
    "# stopwords.extend(more_stopwords)\n",
    "\n",
    "# vocabulary_creator = VocabularyCreator(ngrams_list, **keybert_kwargs)\n",
    "# vocabulary_list = vocabulary_creator.keybert_vocabulary(df4)\n",
    "# bertopic_vectorizer = CountVectorizer(vocabulary=vocabulary_list, stop_words=stopwords, lowercase=True, ngram_range=(1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/cattiaux/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to /home/cattiaux/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/cattiaux/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "### Wordcloud \n",
    "# Lemmatize keywords and recompute their probabilities for the wordcloud image\n",
    "\n",
    "# Download required resources\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "\n",
    "def lemmatize_words(topic_words):\n",
    "    \"\"\"\n",
    "    Lemmatize the words and combine their probabilities.\n",
    "\n",
    "    This function takes as input a list of tuples `topic_words`, where each tuple contains a word and its probability. The function lemmatizes each word using the WordNetLemmatizer from the NLTK library, and combines the probabilities of the lemmas and their inflected forms.\n",
    "\n",
    "    The resulting dictionary, where the keys are the lemmas and the values are their combined probabilities, is then returned.\n",
    "\n",
    "    Parameters:\n",
    "        topic_words (list): A list of tuples, where each tuple contains a word (str) and its probability (float).\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary where the keys are the lemmas (str) and the values are their combined probabilities (float).\n",
    "    \"\"\"\n",
    "    def get_wordnet_pos(treebank_tag):\n",
    "        \"\"\"\n",
    "        Convert NLTK part of speech tags to WordNet tags.\n",
    "\n",
    "        This function takes as input a part of speech tag in the format used by the NLTK library and returns the corresponding WordNet tag. The mapping between NLTK and WordNet tags is as follows:\n",
    "        - 'J' (adjective) maps to `wordnet.ADJ`\n",
    "        - 'V' (verb) maps to `wordnet.VERB`\n",
    "        - 'N' (noun) maps to `wordnet.NOUN`\n",
    "        - 'R' (adverb) maps to `wordnet.ADV`\n",
    "        - All other tags map to `wordnet.NOUN`\n",
    "\n",
    "        Parameters:\n",
    "            treebank_tag (str): The NLTK part of speech tag to be converted.\n",
    "\n",
    "        Returns:\n",
    "            str: The corresponding WordNet part of speech tag.\n",
    "        \"\"\"\n",
    "        if treebank_tag.startswith('J'):\n",
    "            return wordnet.ADJ\n",
    "        elif treebank_tag.startswith('V'):\n",
    "            return wordnet.VERB\n",
    "        elif treebank_tag.startswith('N'):\n",
    "            return wordnet.NOUN\n",
    "        elif treebank_tag.startswith('R'):\n",
    "            return wordnet.ADV\n",
    "        else:\n",
    "            return wordnet.NOUN\n",
    "\n",
    "    # Create a lemmatizer object\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    # Create a dictionary to store the lemmas and their probabilities\n",
    "    lemma_prob = {}\n",
    "\n",
    "    # Lemmatize each word and combine their probabilities\n",
    "    for word, prob in topic_words:\n",
    "        # Tokenize the word and get its part of speech\n",
    "        tokens = nltk.word_tokenize(word)\n",
    "        pos = nltk.pos_tag(tokens)[0][1]\n",
    "        # Get the WordNet part of speech tag\n",
    "        wordnet_pos = get_wordnet_pos(pos)\n",
    "        # Lemmatize the word\n",
    "        lemma = lemmatizer.lemmatize(word, pos=wordnet_pos)\n",
    "        \n",
    "        # Combine the probabilities of the lemma and its inflected forms\n",
    "        if lemma in lemma_prob:\n",
    "            lemma_prob[lemma] += prob\n",
    "        else:\n",
    "            lemma_prob[lemma] = prob\n",
    "    \n",
    "    return lemma_prob\n",
    "\n",
    "def recalculate_probabilities(lemma_prob, docs, topic_model):\n",
    "    \"\"\"\n",
    "    Recalculate the c-TF-IDF scores for the lemmas.\n",
    "\n",
    "    This function takes as input a dictionary `lemma_prob` containing the lemmas and their probabilities, a list of documents `docs`, and a BERTopic model `topic_model`. The function recalculates the c-TF-IDF scores for the lemmas using the provided documents and BERTopic model.\n",
    "\n",
    "    The function first calculates the term frequencies for each lemma using the CountVectorizer from the BERTopic model. Then, it calculates the inverse document frequencies for each lemma and uses these values to compute the c-TF-IDF scores. The c-TF-IDF scores are then normalized and used to update the probabilities of the lemmas.\n",
    "\n",
    "    The resulting dictionary, where the keys are the lemmas and the values are their updated probabilities, is then returned.\n",
    "\n",
    "    Parameters:\n",
    "        lemma_prob (dict): A dictionary where the keys are the lemmas (str) and the values are their probabilities (float).\n",
    "        docs (list): A list of documents used to fit the BERTopic model.\n",
    "        topic_model (BERTopic): The BERTopic model used to calculate the c-TF-IDF scores.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary where the keys are the lemmas (str) and the values are their updated probabilities (float).\n",
    "    \"\"\"\n",
    "    # Calculate the term frequencies using the provided CountVectorizer\n",
    "    X = topic_model.vectorizer_model.transform(docs)\n",
    "    \n",
    "    # Calculate the term frequencies for each lemma\n",
    "    tf = {}\n",
    "    for lemma, prob in lemma_prob.items():\n",
    "        index = topic_model.vectorizer_model.vocabulary_.get(lemma)\n",
    "        if index is not None:\n",
    "            tf[lemma] = np.sum(X[:, index])\n",
    "\n",
    "    # Calculate the inverse document frequencies for each lemma\n",
    "    df = np.sum(X > 0, axis=0)\n",
    "    N = X.shape[0]\n",
    "    idf = np.log(N / (df + 1))\n",
    "\n",
    "    # Calculate the c-TF-IDF scores for each lemma and normalize them\n",
    "    c_tf_idf = {}\n",
    "    for lemma, prob in lemma_prob.items():\n",
    "        index = topic_model.vectorizer_model.vocabulary_.get(lemma)\n",
    "        if index is not None:\n",
    "            c_tf_idf[lemma] = tf[lemma] * idf[0, index]\n",
    "    c_tf_idf_sum = np.sum(list(c_tf_idf.values()))\n",
    "    for lemma, score in c_tf_idf.items():\n",
    "        c_tf_idf[lemma] /= c_tf_idf_sum\n",
    "\n",
    "    # Update the probabilities of the lemmas based on their c-TF-IDF scores\n",
    "    new_lemma_prob = {}\n",
    "    for lemma, prob in lemma_prob.items():\n",
    "        if lemma in c_tf_idf:\n",
    "            new_lemma_prob[lemma] = c_tf_idf[lemma]\n",
    "    \n",
    "    return new_lemma_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Wordcloud\n",
    "\n",
    "def get_topic_words(bertopic_model, topic, top_n=10):\n",
    "    \"\"\"\n",
    "    Get the top n words for a given topic.\n",
    "\n",
    "    This function takes as input a BERTopic model `topic_model`, a topic number `topic`, and an optional integer parameter `top_n` specifying the number of words to return. The function returns the top n words for the given topic, along with their probabilities, as a list of tuples.\n",
    "\n",
    "    The function first retrieves the c-TF-IDF matrix and feature names from the BERTopic model. Then, it gets the row of the c-TF-IDF matrix corresponding to the given topic and uses it to find the indices of the top n words. Finally, it retrieves the words and their probabilities and returns them as a list of tuples.\n",
    "\n",
    "    Parameters:\n",
    "        topic_model (BERTopic): The BERTopic model used to calculate the topic words.\n",
    "        topic (int): The topic number for which to retrieve the top n words.\n",
    "        top_n (int): An optional integer parameter specifying the number of words to return. Defaults to 10.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of tuples, where each tuple contains a word (str) and its probability (float).\n",
    "    \"\"\"\n",
    "    # Get the c-TF-IDF matrix and feature names\n",
    "    c_tf_idf = bertopic_model.c_tf_idf_.toarray()\n",
    "    feature_names = bertopic_model.vectorizer_model.get_feature_names_out()\n",
    "    \n",
    "    # Get the row of the c-TF-IDF matrix corresponding to the topic\n",
    "    topic_row = c_tf_idf[topic]\n",
    "    \n",
    "    # Get the indices of the top_n words for the topic\n",
    "    top_n_indices = np.argsort(topic_row)[::-1][:top_n]\n",
    "    \n",
    "    # Get the words and their probabilities\n",
    "    words = [feature_names[i] for i in top_n_indices]\n",
    "    probabilities = [topic_row[i] for i in top_n_indices]\n",
    "    \n",
    "    # Return the words and their probabilities as a list of tuples\n",
    "    return list(zip(words, probabilities))\n",
    "\n",
    "def group_docs_by_topic(docs, bertopic_model):\n",
    "    \"\"\"\n",
    "    Group documents by their assigned topic.\n",
    "\n",
    "    This function takes as input a list of documents `docs` and a BERTopic model `bertopic_model`. It creates a dictionary where the keys are topic numbers and the values are lists of documents assigned to each topic.\n",
    "\n",
    "    Parameters:\n",
    "        docs (list): A list of documents used to fit the BERTopic model.\n",
    "        bertopic_model (BERTopic): The BERTopic model used to assign topics to the documents.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary where the keys are topic numbers (int) and the values are lists of documents (list) assigned to each topic.\n",
    "    \"\"\"\n",
    "    docs_by_topic = {}\n",
    "    for doc, topic in zip(docs, bertopic_model.topics_):\n",
    "        if topic+1 not in docs_by_topic:\n",
    "            docs_by_topic[topic+1] = []\n",
    "        docs_by_topic[topic+1].append(doc)\n",
    "    \n",
    "    return docs_by_topic \n",
    "\n",
    "def get_word_freq(bertopic_model, docs, topic, top_n=10, scale=1, lemmatize=False):\n",
    "    \"\"\"\n",
    "    Get the word frequencies for a given topic.\n",
    "\n",
    "    This function takes as input a BERTopic model `bertopic_model`, a list of documents `docs`, a topic number `topic`, an optional integer parameter `top_n` specifying the number of words to include, an optional float parameter `scale` used to scale the probabilities of the words and an optional boolean parameter `lemmatize` which determines whether to lemmatize the words before calculating their frequencies.\n",
    "\n",
    "    The function first retrieves the top n words for the given topic using the `get_topic_words` function and scales their probabilities using the provided `scale` parameter. If `lemmatize` is `True`, the function lemmatizes the words using the `lemmatize_words` function and recalculates their probabilities using the `recalculate_probabilities` function. Otherwise, it uses the original words and their probabilities.\n",
    "\n",
    "    Parameters:\n",
    "        bertopic_model (BERTopic): The BERTopic model used to calculate the topic words.\n",
    "        docs (list): A list of documents used to fit the BERTopic model.\n",
    "        topic (int): The topic number for which to calculate the word frequencies.\n",
    "        top_n (int): An optional integer parameter specifying the number of words to include. Defaults to 10.\n",
    "        scale (float): An optional float parameter used to scale the probabilities of the words. Defaults to 1.\n",
    "        lemmatize (bool): An optional boolean parameter used to determine whether to lemmatize the words before calculating their frequencies. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary where the keys are the words/lemmas (str) and the values are their probabilities (float).\n",
    "    \"\"\"\n",
    "    # Get the topic words and their probabilities\n",
    "    topic_words = get_topic_words(bertopic_model, topic, top_n=top_n)\n",
    "    # Scale the probabilities\n",
    "    topic_words = [(word, prob ** scale) for word, prob in topic_words]\n",
    "\n",
    "    if lemmatize:\n",
    "        # Group documents by their assigned topic.\n",
    "        docs_by_topic = group_docs_by_topic(docs, bertopic_model)\n",
    "        # get the documents assigned to a specific topic\n",
    "        my_docs = docs_by_topic.get(topic, [])\n",
    "        # Lemmatize the words and combine their probabilities\n",
    "        lemma_prob = lemmatize_words(topic_words)\n",
    "        # Recalculate the c-TF-IDF scores for the lemmas\n",
    "        topic_words_lemma = recalculate_probabilities(lemma_prob, my_docs, bertopic_model)\n",
    "        # Create a dictionary with the lemmas and their probabilities\n",
    "        word_freq = {lemma: prob for lemma, prob in topic_words_lemma.items()}\n",
    "    \n",
    "    else:\n",
    "        # Create a dictionary with the words and their probabilities\n",
    "        word_freq = {word: prob for word, prob in topic_words}\n",
    "    \n",
    "    return word_freq \n",
    "\n",
    "def create_wordcloud(bertopic_model, docs, topic, top_n=10, scale=1, lemmatize=False, stopwords=None, wordcloud_kwargs=None):\n",
    "    \"\"\"\n",
    "    Create a word cloud from a BERTopic model and a topic.\n",
    "\n",
    "    This function takes as input a BERTopic model `topic_model`, a list of documents `docs`, a topic number `topic`, an optional integer parameter `top_n` specifying the number of words to include in the word cloud, an optional float parameter `scale` used to scale the probabilities of the words, an optional boolean parameter `lemmatize` which determines whether to lemmatize the words before creating the word cloud, an optional list of stopwords `stopwords` to be removed from the word cloud, and an optional dictionary of keyword arguments `wordcloud_kwargs` to be passed to the WordCloud constructor.\n",
    "\n",
    "    The function first retrieves the top n words for the given topic using the `get_topic_words` function and scales their probabilities using the provided `scale` parameter. If `lemmatize` is `True`, the function lemmatizes the words using the `lemmatize_words` function and recalculates their probabilities using the `recalculate_probabilities` function. Otherwise, it uses the original words and their probabilities.\n",
    "\n",
    "    The function then removes any stopwords from the list of words (if provided) and creates a word cloud using the WordCloud class from the wordcloud library. The resulting word cloud is then returned.\n",
    "\n",
    "    Parameters:\n",
    "        topic_model (BERTopic): The BERTopic model used to calculate the topic words.\n",
    "        docs (list): A list of documents used to fit the BERTopic model.\n",
    "        topic (int): The topic number for which to create the word cloud.\n",
    "        top_n (int): An optional integer parameter specifying the number of words to include in the word cloud. Defaults to 10.\n",
    "        scale (float): An optional float parameter used to scale the probabilities of the words. Defaults to 1.\n",
    "        lemmatize (bool): An optional boolean parameter used to determine whether to lemmatize the words before creating the word cloud. Defaults to False.\n",
    "        stopwords (list): An optional list of stopwords to be removed from the word cloud. Defaults to None.\n",
    "        wordcloud_kwargs (dict): An optional dictionary of keyword arguments to be passed to the WordCloud constructor. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        wordcloud.WordCloud: The resulting word cloud.\n",
    "    \"\"\"\n",
    "    # Get the word frequencies for a given topic.\n",
    "    word_freq = get_word_freq(bertopic_model, docs, topic, top_n=top_n, scale=scale, lemmatize=lemmatize)\n",
    "\n",
    "    # Remove stopwords from word_freq if provided\n",
    "    if stopwords:\n",
    "        word_freq = {word: freq for word, freq in word_freq.items() if word not in stopwords}\n",
    "    \n",
    "    # Create the word cloud using the words/lemmas and their probabilities\n",
    "    wc = WordCloud(**(wordcloud_kwargs or {}))\n",
    "    wc.generate_from_frequencies(word_freq)\n",
    "\n",
    "    # Display the word cloud\n",
    "    # plt.imshow(wc, interpolation='bilinear')\n",
    "    # plt.axis(\"off\")\n",
    "    # plt.show()\n",
    "    return wc\n",
    "\n",
    "def create_wordclouds_bertopic(bertopic_model, docs, top_n=10, scale=1, lemmatize=False, stopwords=None, wordcloud_kwargs=None, to_save=False, save_path=None):\n",
    "    \"\"\"\n",
    "    Create word clouds for all topics in a BERTopic model.\n",
    "\n",
    "    This function takes as input a BERTopic model `bertopic_model`, a list of documents `docs`, an optional integer parameter `top_n` specifying the number of words to include in each word cloud, an optional float parameter `scale` used to scale the probabilities of the words, an optional boolean parameter `lemmatize` which determines whether to lemmatize the words before creating the word clouds, an optional list of stopwords `stopwords` to be removed from the word clouds, an optional dictionary of keyword arguments `wordcloud_kwargs` to be passed to the WordCloud constructor, an optional boolean parameter `to_save` which determines whether to save the word clouds as image files, and an optional string parameter `save_path` specifying the path where the image files should be saved.\n",
    "\n",
    "    The function first retrieves the topic information from the BERTopic model and sets the index of the resulting DataFrame to be the topic number. Then, it loops over the topic numbers in the DataFrame and calls the `create_wordcloud` function to create a word cloud for each topic. If `to_save` is `True`, it saves each word cloud as an image file at the specified location using the custom name of the topic.\n",
    "\n",
    "    The resulting dictionary, where the keys are the custom names of the topics and the values are their corresponding word clouds, is then returned.\n",
    "\n",
    "    Parameters:\n",
    "        bertopic_model (BERTopic): The BERTopic model used to calculate the topic words.\n",
    "        docs (list): A list of documents used to fit the BERTopic model.\n",
    "        top_n (int): An optional integer parameter specifying the number of words to include in each word cloud. Defaults to 10.\n",
    "        scale (float): An optional float parameter used to scale the probabilities of the words. Defaults to 1.\n",
    "        lemmatize (bool): An optional boolean parameter used to determine whether to lemmatize the words before creating the word clouds. Defaults to False.\n",
    "        stopwords (list): An optional list of stopwords to be removed from each word cloud. Defaults to None.\n",
    "        wordcloud_kwargs (dict): An optional dictionary of keyword arguments to be passed to each WordCloud constructor. Defaults to None.\n",
    "        to_save (bool): An optional boolean parameter used to determine whether to save each word cloud as an image file. Defaults to False.\n",
    "        save_path (str): An optional string parameter specifying the path where each image file should be saved. Only used if `to_save` is True. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary where the keys are the custom names of the topics (str) and the values are their corresponding word clouds (wordcloud.WordCloud).\n",
    "    \"\"\"\n",
    "    # Check that save_path is provided if to_save is True\n",
    "    if to_save and save_path is None:\n",
    "        raise ValueError(\"If to_save is True, save_path must be provided\")\n",
    "    \n",
    "    # Get the topic information\n",
    "    topic_info = bertopic_model.get_topic_info()\n",
    "    # Set the index of the DataFrame to be the topic number\n",
    "    topic_info = topic_info.set_index('Topic')\n",
    "    wc_pics={}\n",
    "    # Loop over the topic numbers in the DataFrame\n",
    "    for topic_number in topic_info.index:\n",
    "        # Get the custom name of the current topic for saving purpose\n",
    "        topic_custom_name = topic_info.loc[topic_number, 'CustomName']\n",
    "        wc_pic = create_wordcloud(bertopic_model, docs, topic_number+1, top_n=top_n, scale=scale, lemmatize=lemmatize, stopwords=stopwords, wordcloud_kwargs=wordcloud_kwargs)\n",
    "        wc_pics.update({topic_custom_name: wc_pic})\n",
    "\n",
    "        if to_save and lemmatize:\n",
    "            wc_pic.to_file(f'{save_path}/{topic_custom_name}_lemmatized.png')\n",
    "        elif to_save and lemmatize==False:\n",
    "            wc_pic.to_file(f'{save_path}/{topic_custom_name}.png')\n",
    "\n",
    "    return wc_pics\n",
    "\n",
    "# examples of default colors for the wordcloud\n",
    "# colormaps = [\n",
    "#     'viridis', 'plasma', 'inferno', 'magma', 'cividis',\n",
    "#     'Greys', 'Purples', 'Blues', 'Greens', 'Oranges',\n",
    "#     'Reds', 'YlOrBr', 'YlOrRd', 'OrRd', 'PuRd',\n",
    "#     'RdPu', 'BuPu', 'GnBu', 'PuBu', 'YlGnBu',\n",
    "#     'PuBuGn', 'BuGn', 'YlGn'\n",
    "# ]\n",
    "\n",
    "# Create a custom colormap\n",
    "# colors = [\"#294D61\", \"#6DA5C0\", \"#0F969C\", \"#0C7075\", \"#072E33\",\"#05161A\"]\n",
    "colors = [\"#F1916D\", \"#F5D7DB\", \"#BD83B8\", \"#473E66\", \"#1B3358\",\"#06142E\"]\n",
    "my_cmap = ListedColormap(colors)\n",
    "\n",
    "# Create a binary mask from an image\n",
    "# make sure that the image is black and white, where black pixels indicate where to draw words and white pixels indicate where not to draw words.\n",
    "# mask = np.array(Image.open('circle.png'))\n",
    "\n",
    "wordcloud_stopwords = [\"get\",\"would\",\"us\",\"good\",\"like\",\"goods\",\"got\",\"able\",\"quite\",\"always\",\"nothing\",\"add\",\"everything\",\"think\",\"gave\",\"due\",\"find\",\"say\",\"took\",\"still\",\"within\",\"22\",\"10\",\"one\",\"makhloufi\",\"saliger\",\"kessler\",\"naldrin\",\"hidde\",\"mohua\",\"possible\",\"since\",\"could\",\"especially\",\"altivar\",\"every\",\"anyway\",\"egawa\",\"sometimes\"]\n",
    "\n",
    "wordcloud_kwargs = {\n",
    "    'width': 800,\n",
    "    'height': 400,\n",
    "    'background_color': 'black',\n",
    "    'contour_width': 100,\n",
    "    'contour_color': 'red',\n",
    "    'colormap': 'GnBu',\n",
    "    \"contour_width\": 5,\n",
    "    \"contour_color\": 'red'\n",
    "    # \"mask\":mask\n",
    "}\n",
    "\n",
    "wordclouds = create_wordclouds_bertopic(topic_model_merged, docs, \n",
    "                           top_n=50, scale=1, \n",
    "                           lemmatize=True, \n",
    "                           stopwords=wordcloud_stopwords, \n",
    "                           wordcloud_kwargs=wordcloud_kwargs,\n",
    "                           to_save=True, \n",
    "                           save_path=\"../data/wordclouds/test2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Barchart from seaborn : emotions by year\n",
    "\n",
    "# # Create a count plot\n",
    "# sns.set(style=\"whitegrid\")\n",
    "# g = sns.catplot(x=\"year\", y=None, hue=\"single_emotion_label\", data=df4, kind=\"count\", height=4, aspect=2)\n",
    "\n",
    "# # Set the axis labels\n",
    "# g.set_axis_labels(\"Year\", \"Count\")\n",
    "\n",
    "# # Set the title\n",
    "# plt.title(\"Count of Emotions by Year\")\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph avec plotly.express : barchart for one defined emotion\n",
    "\n",
    "def plot_emotion(df, emotions_col_name, emotion, year_col_name, nbins=20):\n",
    "    \"\"\"\n",
    "    Plot a histogram of the distribution of a given emotion by year.\n",
    "\n",
    "    This function takes as input a dataframe `df`, an emotion `emotion` and creates a histogram showing the distribution of this emotion by year. The data is filtered to only include rows with the specified emotion, and a histogram is created using the Plotly Express library. The axis labels and title are set, and the resulting plot is shown.\n",
    "\n",
    "    Parameters:\n",
    "        df (pandas.DataFrame): The input dataframe containing the data to be plotted.\n",
    "        emotion (str): The emotion to be plotted.\n",
    "\n",
    "    Returns:\n",
    "        plotly.graph_objs.Figure: The resulting histogram plot.\n",
    "    \"\"\"\n",
    "    # Filter the data to only include rows with the specified emotion\n",
    "    filtered_data = df[df[emotions_col_name] == emotion]\n",
    "    \n",
    "    # Create a histogram\n",
    "    fig = px.histogram(filtered_data, x=year_col_name, nbins=nbins)\n",
    "    \n",
    "    # Set the axis labels\n",
    "    fig.update_layout(xaxis_title='Year', yaxis_title='Count')\n",
    "    \n",
    "    # Set the title\n",
    "    fig.update_layout(title=f'Distribution of {emotion} by Year')\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# # Call the function with the desired emotion\n",
    "# plot_emotion(df4, 'disappointment')\n",
    "\n",
    "## Tests graph précédent avec menu déroulant pour choisir son emotion\n",
    "\n",
    "# # Create a dropdown menu with all unique emotions in 'single_emotion_label' column\n",
    "# emotions = df4['single_emotion_label'].unique()\n",
    "# dropdown = widgets.Dropdown(options=emotions)\n",
    "\n",
    "# # Create an output widget to display the plot\n",
    "# output = widgets.Output()\n",
    "\n",
    "# # Define a function that updates the plot when a new emotion is selected\n",
    "# def on_change(change):\n",
    "#     if change['name'] == 'value':\n",
    "#         with output:\n",
    "#             output.clear_output()\n",
    "#             plot_emotion(change['new'])\n",
    "\n",
    "# # Register the function as a callback for changes in the dropdown value\n",
    "# dropdown.observe(on_change)\n",
    "\n",
    "# # # Display the widgets\n",
    "# display(dropdown)\n",
    "# display(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Graph barchart of one given emotion by a specified class (year, zone, etc.)\n",
    "\n",
    "# Plot a bar chart or histogram of the distribution of a given emotion by a specified class\n",
    "def plot_emotion(df, emotion, class_name, time_period=None, use_percentage=False, random_colors=True, set_colors=['#96ceb4', '#87bdd8', '#ffcc5c', '#ff6f69', '#f4a688', '#d96459'], set_color=None):\n",
    "    \"\"\"\n",
    "    This function plots a bar chart of the distribution of a specified emotion by a specified class.\n",
    "\n",
    "    Parameters:\n",
    "    df (DataFrame): The input dataframe.\n",
    "    emotion (str): The emotion to filter the dataframe by.\n",
    "    class_name (str): The name of the class column in the dataframe.\n",
    "    time_period (int, optional): The time period to filter the dataframe by. Defaults to None.\n",
    "    use_percentage (bool, optional): Whether to calculate and plot percentages instead of counts. Defaults to False.\n",
    "    random_colors (bool, optional): Whether to choose a color randomly from the set_colors list. If False, set_color must be provided. Defaults to True.\n",
    "    set_colors (list of str, optional): The list of colors to choose from if random_colors is True. Defaults to ['#96ceb4', '#87bdd8', '#ffcc5c', '#ff6f69', '#f4a688', '#d96459'].\n",
    "    set_color (str, optional): The color to use for the plot if random_colors is False. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "    Figure: A Plotly figure containing the bar chart.\n",
    "    \"\"\"\n",
    "    # Check that set_color is provided if random_colors is False\n",
    "    if random_colors==False and set_color is None:\n",
    "        raise ValueError(\"set_color must be provided if random_colors is False\")\n",
    "    \n",
    "    # Filter the data to only include rows with the specified emotion\n",
    "    filtered_data = df[df['single_emotion_label'] == emotion]\n",
    "\n",
    "    # Filter the data by the specified time period if provided\n",
    "    if time_period != None:\n",
    "        if class_name == 'year':\n",
    "            raise ValueError(\"class_name cannot be 'year' when time_period is defined\")\n",
    "        filtered_data = filtered_data[filtered_data['year'] == time_period]\n",
    "\n",
    "    if random_colors:\n",
    "        # Randomly choose a color from the defined colors list\n",
    "        colors_list = set_colors\n",
    "        color = random.choice(colors_list)\n",
    "    else:\n",
    "        color = set_color\n",
    "\n",
    "    # Calculate the percentage if use_percentage is True\n",
    "    if use_percentage:\n",
    "        total_per_zone = df.groupby(class_name).size()\n",
    "        filtered_data = (filtered_data[class_name].value_counts() / total_per_zone * 100).reset_index()\n",
    "        filtered_data.columns = [class_name, 'percentage']\n",
    "        y_value = 'percentage'\n",
    "    else:\n",
    "        filtered_data = filtered_data[class_name].value_counts().reset_index()\n",
    "        filtered_data.columns = [class_name, 'count']\n",
    "        y_value = 'count'\n",
    "\n",
    "    # Sort the data by ascending frequency if class_name is not 'year'\n",
    "    if class_name != 'year':\n",
    "        filtered_data.sort_values(by=y_value, ascending=True, inplace=True)\n",
    "\n",
    "    fig = px.bar(filtered_data, x=class_name, y=y_value, color_discrete_sequence=[color], width=1100, height=600)\n",
    "\n",
    "    # Set the axis labels\n",
    "    fig.update_layout(xaxis_title=class_name, yaxis_title=y_value)\n",
    "    # Set the title\n",
    "    fig.update_layout(title=f'Distribution of {emotion} by {class_name}' + (f' in {time_period}' if time_period is not None else ''))\n",
    "    # Center the title\n",
    "    fig.update_layout(title_x=0.5)\n",
    "\n",
    "    return fig\n",
    "\n",
    "emotions = df4['single_emotion_label'].unique()\n",
    "class_name = \"year\"\n",
    "time_period = None\n",
    "# Loop over each emotion and save the corresponding graph\n",
    "for emotion in emotions:\n",
    "    fig = plot_emotion(df4, emotion, class_name, time_period, use_percentage=True)\n",
    "    # Export the chart as a PNG image\n",
    "    pio.write_image(fig, f'../data/graphs/Sentiment_Analysis/by_emotion/repartition/by_{class_name}/{emotion}_pct.png')\n",
    "\n",
    "# plot_emotion(df4, \"admiration\", \"Zone\", time_period=None, use_percentage=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_top_topic_docs(probabilities, df, topic, top_n_docs=len(df)):\n",
    "    \"\"\"\n",
    "    Get the top n documents for a specified topic.\n",
    "\n",
    "    Parameters:\n",
    "    probabilities (numpy.ndarray): The probabilities from the BERTopic model.\n",
    "    df (pandas.DataFrame): The dataframe containing the documents.\n",
    "    topic (int): The topic to get the top n documents for.\n",
    "    top_n_docs (int): The number of top documents to return. Defaults to the length of df.\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing a dataframe with the top n documents for the specified topic and a list with their content.\n",
    "    \"\"\"\n",
    "    def sort_docs_with_same_prob(probabilities, prob, topic):\n",
    "        \"\"\"\n",
    "        Sort documents that have the same probability for a specified topic.\n",
    "\n",
    "        Parameters:\n",
    "        probabilities (numpy.ndarray): The probabilities from the BERTopic model.\n",
    "        prob (float): The probability to filter by.\n",
    "        topic (int): The topic to sort the documents for.\n",
    "\n",
    "        Returns:\n",
    "        numpy.ndarray: An array containing the sorted indices of the documents that have the specified probability for the specified topic.\n",
    "        \"\"\"\n",
    "        # Get the indices of all documents that have the current probability for the defined topic\n",
    "        top_docs_indices = np.where(probabilities[:, topic] == prob)[0]\n",
    "        # Sort the probabilities for each document in descending order\n",
    "        sorted_probs = -np.sort(-probabilities[top_docs_indices], axis=1)\n",
    "        # Compute the score for each document based on the difference between their first and second scores\n",
    "        scores = sorted_probs[:, 0] - sorted_probs[:, 1]\n",
    "        # Sort these top documents based on their scores\n",
    "        sorted_top_docs_indices = top_docs_indices[np.argsort(scores)[::-1]]\n",
    "        \n",
    "        return sorted_top_docs_indices\n",
    "    \n",
    "    # Get the unique probabilities for the defined topic\n",
    "    unique_probs = np.unique(probabilities[:, topic])\n",
    "    # Sort the unique probabilities in descending order\n",
    "    sorted_unique_probs = np.sort(unique_probs)[::-1]\n",
    "    \n",
    "    # Initialize an empty list to store the sorted indices of all documents\n",
    "    sorted_docs_indices = []\n",
    "    \n",
    "    # Loop over the unique probabilities\n",
    "    for prob in sorted_unique_probs:\n",
    "        # Sort the documents that have the current probability for the defined topic\n",
    "        sorted_top_docs_indices = sort_docs_with_same_prob(probabilities, prob, topic)\n",
    "        # Append these indices to the list of sorted indices of all documents\n",
    "        sorted_docs_indices.extend(sorted_top_docs_indices)\n",
    "    \n",
    "    # Take the top n from this sorted list\n",
    "    final_top_docs_indices = np.array(sorted_docs_indices)[:top_n_docs]\n",
    "    \n",
    "    # Get the content of the top n documents from your dataframe\n",
    "    top_docs_df = df.iloc[final_top_docs_indices]\n",
    "    top_docs_content = top_docs_df[\"processed_data\"].to_list()\n",
    "    \n",
    "    return top_docs_df, top_docs_content\n",
    "\n",
    "def filter_docs(df, filter_column, filter_value):\n",
    "    \"\"\"\n",
    "    Filter a dataframe based on a specified column and value.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): The dataframe to filter.\n",
    "    filter_column (str): The name of the column to filter by.\n",
    "    filter_value (str): The value to filter by in the specified column.\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing the filtered dataframe and a boolean mask indicating which rows match the specified filter.\n",
    "    \"\"\"\n",
    "    filter_mask = df[filter_column] == filter_value\n",
    "    return df[filter_mask], filter_mask\n",
    "\n",
    "# Filter the top docs based on the specified column and value\n",
    "filtered_top_docs, filter_mask = filter_docs(df4, \"Account Country\", \"France\")\n",
    "top_docs_df, top_docs_content = get_top_topic_docs(topic_model_merged.probabilities_[filter_mask], filtered_top_docs, topic=2, top_n_docs=10)\n",
    "\n",
    "# top_docs_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wassati",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
